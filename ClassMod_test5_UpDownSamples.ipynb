{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fastparquet import ParquetFile,write\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from tqdm import tqdm\n",
    "\n",
    "from cm2df import cm2df,precision_recall_fscore_support_metrics2df\n",
    "from sklearn.metrics import confusion_matrix, classification_report,precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf=ParquetFile('subset_feature_4ML_110619.parq')\n",
    "udf=pf.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32880 entries, 11049447 to 9968570\n",
      "Data columns (total 35 columns):\n",
      "category                 32880 non-null int64\n",
      "past                     32880 non-null int32\n",
      "votes                    32880 non-null int64\n",
      "is_eventbrite            32880 non-null int32\n",
      "is_free                  32880 non-null int32\n",
      "doors                    32880 non-null int32\n",
      "sold_out                 32880 non-null int32\n",
      "venue.id                 32880 non-null int64\n",
      "venue.popularity         32880 non-null float64\n",
      "venue.zip                32880 non-null int64\n",
      "ticket_allages           32880 non-null int32\n",
      "ticket_price_low         32880 non-null float64\n",
      "ticket_price_max         32880 non-null float64\n",
      "min_age                  32880 non-null int32\n",
      "artist.popularity.sum    32880 non-null float64\n",
      "artist.popularity.avg    32880 non-null float64\n",
      "artist.popularity.max    32880 non-null float64\n",
      "dow                      32880 non-null int64\n",
      "doy                      32880 non-null int64\n",
      "month                    32880 non-null int64\n",
      "day                      32880 non-null int64\n",
      "hour                     32880 non-null int64\n",
      "venue.tol_num_events     32880 non-null int64\n",
      "ev_id                    32880 non-null int64\n",
      "title                    32880 non-null object\n",
      "venue.title              32880 non-null object\n",
      "venue.address            32806 non-null object\n",
      "venue.city               32880 non-null object\n",
      "venue.state              32880 non-null object\n",
      "venue.latitude           32880 non-null float64\n",
      "venue.longitude          32880 non-null float64\n",
      "duration                 32880 non-null float64\n",
      "duration_day             32880 non-null float64\n",
      "multiday                 32880 non-null bool\n",
      "avg_votes_pday           32880 non-null float64\n",
      "dtypes: bool(1), float64(11), int32(7), int64(11), object(5)\n",
      "memory usage: 7.9+ MB\n"
     ]
    }
   ],
   "source": [
    "udf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf['multiday'] = udf['multiday'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecolsX=['category', 'past', 'is_eventbrite', 'is_free', 'doors',\n",
    "       'sold_out', 'venue.id', 'venue.popularity', 'venue.zip',\n",
    "       'ticket_allages', 'ticket_price_low', 'ticket_price_max', 'min_age',\n",
    "       'artist.popularity.sum', 'artist.popularity.avg',\n",
    "       'artist.popularity.max', 'dow', 'doy', 'month', 'day', 'hour',\n",
    "       'venue.tol_num_events', 'duration', 'duration_day', 'multiday']\n",
    "usecoly1=['votes']\n",
    "usecoly2=['avg_votes_pday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_X=udf[usecolsX]\n",
    "udf_y=udf[usecoly1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to create udf_y based on 3 classes: low, mid, high\n",
    "def get_class(df,thre1,thre2):\n",
    "    n=len(df)\n",
    "    newdf=[]\n",
    "    cut1=min([thre1,thre2])\n",
    "    cut2=max([thre1,thre2])\n",
    "    for item in df:\n",
    "        if item<cut1: newdf+=[0]\n",
    "        elif (item<cut2) and (item>=cut1):newdf+=[1]\n",
    "        else: newdf+=[2]\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=get_class(udf_y.values,80,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaling of the features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# scale regression dataset\n",
    "scalar = MinMaxScaler()\n",
    "scalar.fit(udf_X)\n",
    "X = scalar.transform(udf_X)\n",
    "# import algorithms for model comparisons\n",
    "# tree models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import algorithms for model comparisons\n",
    "# tree models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "# setup the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Model: Random Forest> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecolsX=['category', 'past', 'is_eventbrite', 'is_free', 'doors',\n",
    "       'sold_out', 'venue.id', 'venue.popularity', 'venue.zip',\n",
    "       'ticket_allages', 'ticket_price_low', 'ticket_price_max', 'min_age',\n",
    "       'artist.popularity.sum', 'artist.popularity.avg',\n",
    "       'artist.popularity.max', 'dow', 'doy', 'month', 'day', 'hour',\n",
    "       'venue.tol_num_events', 'duration', 'duration_day', 'multiday']\n",
    "usecoly1=['votes']\n",
    "usecoly2=['avg_votes_pday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_X=udf[usecolsX+['votes']]\n",
    "udf_y=udf[usecoly1]\n",
    "y=get_class(udf_y.values,80,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of low votes: 31611\n",
      "number of medium votes: 1059\n",
      "number of high votes: 210\n",
      "number of features: 26\n"
     ]
    }
   ],
   "source": [
    "print(\"number of low votes:\",list(y).count(0))\n",
    "print(\"number of medium votes:\",list(y).count(1))\n",
    "print(\"number of high votes:\",list(y).count(2))\n",
    "print(\"number of features:\",len(udf_X.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the training data:\n",
      "number of low votes: 22128\n",
      "number of medium votes: 741\n",
      "number of high votes: 147\n",
      "in the testing data:\n",
      "number of low votes: 9483\n",
      "number of medium votes: 318\n",
      "number of high votes: 63\n"
     ]
    }
   ],
   "source": [
    "# first spare the training data for upsampling\n",
    "X_train, X_test, y_train, y_test = train_test_split(udf_X, y, test_size=0.3, stratify=y, random_state=12)\n",
    "print(\"in the training data:\")\n",
    "print(\"number of low votes:\",list(y_train).count(0))\n",
    "print(\"number of medium votes:\",list(y_train).count(1))\n",
    "print(\"number of high votes:\",list(y_train).count(2))\n",
    "print(\"in the testing data:\")\n",
    "print(\"number of low votes:\",list(y_test).count(0))\n",
    "print(\"number of medium votes:\",list(y_test).count(1))\n",
    "print(\"number of high votes:\",list(y_test).count(2))\n",
    "# do upsample with replacement\n",
    "from sklearn.utils import resample\n",
    "# separate three classes\n",
    "# add back the 'votes' column, and redo the sampling\n",
    "mask0=[True if x==0 else False for x in y_train]\n",
    "mask1=[True if x==1 else False for x in y_train]\n",
    "mask2=[True if x==2 else False for x in y_train]\n",
    "class0=X_train.loc[mask0]\n",
    "class1=X_train.loc[mask1]\n",
    "class2=X_train.loc[mask2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Very Aggresssive upsample of the high votes: upsample high votes to be same as medium (3.5 times more than original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2_upsampled = resample(class2, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=int(len(class1)*1),    # to upsample to 100% of medium\n",
    "                                 random_state=12) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix all samples\n",
    "ndf=pd.concat([class0,class1,df_2_upsampled])\n",
    "# re-shuffle the order\n",
    "ndf=ndf.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase sample size on the percentage: 2.5808133472367047 %\n"
     ]
    }
   ],
   "source": [
    "print(\"increase sample size on the percentage:\",(len(ndf)-len(X_train))/len(X_train)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the target classes, and then drop the votes from X data\n",
    "yy=get_class(ndf['votes'].values,80,300)\n",
    "ndf=ndf[usecolsX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the upsampled training data:\n",
      "number of low votes: 22128\n",
      "number of medium votes: 6638\n",
      "number of high votes: 741 ,compared with original: 210\n",
      "number of features in X: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"in the upsampled training data:\")\n",
    "print(\"number of low votes:\",list(yy).count(0))\n",
    "print(\"number of medium votes:\",list(yy).count(1))\n",
    "print(\"number of high votes:\",list(yy).count(2),\",compared with original:\",list(y).count(2))\n",
    "print(\"number of features in X:\",len(ndf.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redo the benchmark model\n",
    "scalar = MinMaxScaler()\n",
    "scalar.fit(ndf)\n",
    "X = scalar.transform(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spare the X_test with proper versions\n",
    "X_test=X_test[usecolsX]\n",
    "X_test=scalar.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_rec=[]\n",
    "recal_rec=[]\n",
    "max_f=len(udf_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4760812469154372\n"
     ]
    }
   ],
   "source": [
    "classifier=RandomForestClassifier(n_estimators=80,random_state=12,max_features=int(max_f*0.75),verbose=0)\n",
    "classifier.fit(X_train,y_train)\n",
    "pred_y_test=classifier.predict(X_test)\n",
    "# assess the model performance: obtain prescision/recall/f1 scores\n",
    "a=precision_recall_fscore_support(y_test, pred_y_test)\n",
    "f1s=a[2]\n",
    "prec_rec+=[a[0]]\n",
    "recal_rec+=[a[1]]\n",
    "# create the weighted f1 score: larger emphasis on high-votes bin and medium\n",
    "# adjusted f1_forall= (f1_low+f1_mid*2+f1_high*3)/6\n",
    "adjf1=(f1s[0]+f1s[1]*2+f1s[2]*3)/6\n",
    "print(adjf1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[22127     1     0]\n",
      " [    1   740     0]\n",
      " [    0     0   147]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     22128\n",
      "           1       1.00      1.00      1.00       741\n",
      "           2       1.00      1.00      1.00       147\n",
      "\n",
      "    accuracy                           1.00     23016\n",
      "   macro avg       1.00      1.00      1.00     23016\n",
      "weighted avg       1.00      1.00      1.00     23016\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y_train=classifier.predict(X_train)\n",
    "# print confusion matrix-- training\n",
    "print(\"confusion matrix:\",confusion_matrix(y_train, pred_y_train))\n",
    "print(\"other metrics:\",classification_report(y_train, pred_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[9437   41    5]\n",
      " [ 209  106    3]\n",
      " [  34   15   14]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      9483\n",
      "           1       0.65      0.33      0.44       318\n",
      "           2       0.64      0.22      0.33        63\n",
      "\n",
      "    accuracy                           0.97      9864\n",
      "   macro avg       0.76      0.52      0.59      9864\n",
      "weighted avg       0.96      0.97      0.96      9864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix\n",
    "print(\"confusion matrix:\",confusion_matrix(y_test, pred_y_test))\n",
    "print(\"other metrics:\",classification_report(y_test, pred_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.509652137879281\n"
     ]
    }
   ],
   "source": [
    "classifier0=RandomForestClassifier(n_estimators=90,random_state=12,max_features=int(max_f*0.75),verbose=0)\n",
    "classifier0.fit(X,yy)\n",
    "pred_y_test=classifier0.predict(X_test)\n",
    "# assess the model performance: obtain prescision/recall/f1 scores\n",
    "a=precision_recall_fscore_support(y_test, pred_y_test)\n",
    "f1s=a[2]\n",
    "prec_rec+=[a[0]]\n",
    "recal_rec+=[a[1]]\n",
    "# create the weighted f1 score: larger emphasis on high-votes bin and medium\n",
    "# adjusted f1_forall= (f1_low+f1_mid*2+f1_high*3)/6\n",
    "adjf1=(f1s[0]+f1s[1]*2+f1s[2]*3)/6\n",
    "print(adjf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[22127     1     0]\n",
      " [    0   741     0]\n",
      " [    0     0   741]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     22128\n",
      "           1       1.00      1.00      1.00       741\n",
      "           2       1.00      1.00      1.00       741\n",
      "\n",
      "    accuracy                           1.00     23610\n",
      "   macro avg       1.00      1.00      1.00     23610\n",
      "weighted avg       1.00      1.00      1.00     23610\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y_train=classifier0.predict(X)\n",
    "# print confusion matrix-- training\n",
    "print(\"confusion matrix:\",confusion_matrix(yy, pred_y_train))\n",
    "print(\"other metrics:\",classification_report(yy, pred_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[9434   37   12]\n",
      " [ 215   97    6]\n",
      " [  31   11   21]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      9483\n",
      "           1       0.67      0.31      0.42       318\n",
      "           2       0.54      0.33      0.41        63\n",
      "\n",
      "    accuracy                           0.97      9864\n",
      "   macro avg       0.73      0.54      0.61      9864\n",
      "weighted avg       0.96      0.97      0.96      9864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix-- testing\n",
    "print(\"confusion matrix:\",confusion_matrix(y_test, pred_y_test))\n",
    "print(\"other metrics:\",classification_report(y_test, pred_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Very Aggresssive upsample of the medium votes: upsample medium votes to be 30% as low votes (~6.3 times more than original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_upsampled = resample(class1, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=int(len(class0)*.3),    # to upsample to 30% of low\n",
    "                                 random_state=12) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix all samples\n",
    "ndf=pd.concat([class0,df_1_upsampled,df_2_upsampled])\n",
    "# re-shuffle the order\n",
    "ndf=ndf.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase sample size on the percentage: 28.20212026416406 %\n"
     ]
    }
   ],
   "source": [
    "print(\"increase sample size on the percentage:\",(len(ndf)-len(X_train))/len(X_train)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the target classes, and then drop the votes from X data\n",
    "yy=get_class(ndf['votes'].values,80,300)\n",
    "ndf=ndf[usecolsX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the upsampled training data:\n",
      "number of low votes: 22128\n",
      "number of medium votes: 6638 ,compared with original: 1059\n",
      "number of high votes: 741 ,compared with original: 210\n",
      "number of features in X: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"in the upsampled training data:\")\n",
    "print(\"number of low votes:\",list(yy).count(0))\n",
    "print(\"number of medium votes:\",list(yy).count(1),\",compared with original:\",list(y).count(1))\n",
    "print(\"number of high votes:\",list(yy).count(2),\",compared with original:\",list(y).count(2))\n",
    "print(\"number of features in X:\",len(ndf.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redo the benchmark model\n",
    "scalar = MinMaxScaler()\n",
    "scalar.fit(ndf)\n",
    "X = scalar.transform(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4897649059210892\n"
     ]
    }
   ],
   "source": [
    "classifier1=RandomForestClassifier(n_estimators=90,random_state=12,max_features=int(max_f*0.75),verbose=0)\n",
    "classifier1.fit(X,yy)\n",
    "pred_y_test=classifier1.predict(X_test)\n",
    "# assess the model performance: obtain prescision/recall/f1 scores\n",
    "a=precision_recall_fscore_support(y_test, pred_y_test)\n",
    "f1s=a[2]\n",
    "prec_rec+=[a[0]]\n",
    "recal_rec+=[a[1]]\n",
    "# create the weighted f1 score: larger emphasis on high-votes bin and medium\n",
    "# adjusted f1_forall= (f1_low+f1_mid*2+f1_high*3)/6\n",
    "adjf1=(f1s[0]+f1s[1]*2+f1s[2]*3)/6\n",
    "print(adjf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[22127     1     0]\n",
      " [    0  6638     0]\n",
      " [    0     0   741]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     22128\n",
      "           1       1.00      1.00      1.00      6638\n",
      "           2       1.00      1.00      1.00       741\n",
      "\n",
      "    accuracy                           1.00     29507\n",
      "   macro avg       1.00      1.00      1.00     29507\n",
      "weighted avg       1.00      1.00      1.00     29507\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y_train=classifier1.predict(X)\n",
    "# print confusion matrix-- training\n",
    "print(\"confusion matrix:\",confusion_matrix(yy, pred_y_train))\n",
    "print(\"other metrics:\",classification_report(yy, pred_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[9403   69   11]\n",
      " [ 179  131    8]\n",
      " [  27   20   16]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      9483\n",
      "           1       0.60      0.41      0.49       318\n",
      "           2       0.46      0.25      0.33        63\n",
      "\n",
      "    accuracy                           0.97      9864\n",
      "   macro avg       0.68      0.55      0.60      9864\n",
      "weighted avg       0.96      0.97      0.96      9864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix-- testing\n",
    "print(\"confusion matrix:\",confusion_matrix(y_test, pred_y_test))\n",
    "print(\"other metrics:\",classification_report(y_test, pred_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale down the medium votes upsampling: use a 20% of the low votes(~4 times more than original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_upsampled = resample(class1, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=int(len(class0)*.2),    # to upsample to 20% of low\n",
    "                                 random_state=12) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix all samples\n",
    "ndf=pd.concat([class0,df_1_upsampled,df_2_upsampled])\n",
    "# re-shuffle the order\n",
    "ndf=ndf.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase sample size on the percentage: 18.587069864442128 %\n"
     ]
    }
   ],
   "source": [
    "print(\"increase sample size on the percentage:\",(len(ndf)-len(X_train))/len(X_train)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the target classes, and then drop the votes from X data\n",
    "yy=get_class(ndf['votes'].values,80,300)\n",
    "ndf=ndf[usecolsX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the upsampled training data:\n",
      "number of low votes: 22128\n",
      "number of medium votes: 4425 ,compared with original: 1059\n",
      "number of high votes: 741 ,compared with original: 210\n",
      "number of features in X: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"in the upsampled training data:\")\n",
    "print(\"number of low votes:\",list(yy).count(0))\n",
    "print(\"number of medium votes:\",list(yy).count(1),\",compared with original:\",list(y).count(1))\n",
    "print(\"number of high votes:\",list(yy).count(2),\",compared with original:\",list(y).count(2))\n",
    "print(\"number of features in X:\",len(ndf.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redo the benchmark model\n",
    "scalar = MinMaxScaler()\n",
    "scalar.fit(ndf)\n",
    "X = scalar.transform(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48872754993361633\n"
     ]
    }
   ],
   "source": [
    "classifier2=RandomForestClassifier(n_estimators=90,random_state=12,max_features=int(max_f*.75),verbose=0)\n",
    "classifier2.fit(X,yy)\n",
    "pred_y_test=classifier2.predict(X_test)\n",
    "# assess the model performance: obtain prescision/recall/f1 scores\n",
    "a=precision_recall_fscore_support(y_test, pred_y_test)\n",
    "f1s=a[2]\n",
    "prec_rec+=[a[0]]\n",
    "recal_rec+=[a[1]]\n",
    "# create the weighted f1 score: larger emphasis on high-votes bin and medium\n",
    "# adjusted f1_forall= (f1_low+f1_mid*2+f1_high*3)/6\n",
    "adjf1=(f1s[0]+f1s[1]*2+f1s[2]*3)/6\n",
    "print(adjf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[22127     1     0]\n",
      " [    0  4425     0]\n",
      " [    0     0   741]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     22128\n",
      "           1       1.00      1.00      1.00      4425\n",
      "           2       1.00      1.00      1.00       741\n",
      "\n",
      "    accuracy                           1.00     27294\n",
      "   macro avg       1.00      1.00      1.00     27294\n",
      "weighted avg       1.00      1.00      1.00     27294\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y_train=classifier2.predict(X)\n",
    "# print confusion matrix-- training\n",
    "print(\"confusion matrix:\",confusion_matrix(yy, pred_y_train))\n",
    "print(\"other metrics:\",classification_report(yy, pred_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[9401   70   12]\n",
      " [ 186  127    5]\n",
      " [  26   21   16]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      9483\n",
      "           1       0.58      0.40      0.47       318\n",
      "           2       0.48      0.25      0.33        63\n",
      "\n",
      "    accuracy                           0.97      9864\n",
      "   macro avg       0.68      0.55      0.60      9864\n",
      "weighted avg       0.96      0.97      0.96      9864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix-- testing\n",
    "print(\"confusion matrix:\",confusion_matrix(y_test, pred_y_test))\n",
    "print(\"other metrics:\",classification_report(y_test, pred_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### compare to both training and testing case, apparently model is overfitted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try upsampling for medium and high votes to the same level (30% of the low votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upsampled to: 6638\n"
     ]
    }
   ],
   "source": [
    "# try scale down the ratio of upsampling\n",
    "df_2_upsampled = resample(class2, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=int(len(class0)*.3),    # to upsample to 30% of low\n",
    "                                 random_state=12) # reproducible results\n",
    "print(\"upsampled to:\",len(df_2_upsampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upsampled to: 6638\n"
     ]
    }
   ],
   "source": [
    "df_1_upsampled = resample(class1, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=int(len(class0)*.3),    # to upsample to 30% of low\n",
    "                                 random_state=12) # reproducible results\n",
    "print(\"upsampled to:\",len(df_1_upsampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix all samples\n",
    "ndf=pd.concat([class0,df_1_upsampled,df_2_upsampled])\n",
    "# re-shuffle the order\n",
    "ndf=ndf.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase sample size on the percentage: 53.82342718109141 %\n"
     ]
    }
   ],
   "source": [
    "print(\"increase sample size on the percentage:\",(len(ndf)-len(X_train))/len(X_train)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the target classes, and then drop the votes from X data\n",
    "yy=get_class(ndf['votes'].values,80,300)\n",
    "ndf=ndf[usecolsX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the upsampled training data:\n",
      "number of low votes: 22128\n",
      "number of medium votes: 6638 ,compared with original: 1059\n",
      "number of high votes: 6638 ,compared with original: 210\n",
      "number of features in X: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"in the upsampled training data:\")\n",
    "print(\"number of low votes:\",list(yy).count(0))\n",
    "print(\"number of medium votes:\",list(yy).count(1),\",compared with original:\",list(y).count(1))\n",
    "print(\"number of high votes:\",list(yy).count(2),\",compared with original:\",list(y).count(2))\n",
    "print(\"number of features in X:\",len(ndf.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale data input\n",
    "scalar = MinMaxScaler()\n",
    "scalar.fit(ndf)\n",
    "X = scalar.transform(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48810479126763634\n"
     ]
    }
   ],
   "source": [
    "classifier3=RandomForestClassifier(n_estimators=90,random_state=12,max_features=int(max_f*.75),verbose=0)\n",
    "classifier3.fit(X,yy)\n",
    "pred_y_test=classifier3.predict(X_test)\n",
    "# assess the model performance: obtain prescision/recall/f1 scores\n",
    "a=precision_recall_fscore_support(y_test, pred_y_test)\n",
    "f1s=a[2]\n",
    "prec_rec+=[a[0]]\n",
    "recal_rec+=[a[1]]\n",
    "# create the weighted f1 score: larger emphasis on high-votes bin and medium\n",
    "# adjusted f1_forall= (f1_low+f1_mid*2+f1_high*3)/6\n",
    "adjf1=(f1s[0]+f1s[1]*2+f1s[2]*3)/6\n",
    "print(adjf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[22127     1     0]\n",
      " [    0  6638     0]\n",
      " [    0     0  6638]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     22128\n",
      "           1       1.00      1.00      1.00      6638\n",
      "           2       1.00      1.00      1.00      6638\n",
      "\n",
      "    accuracy                           1.00     35404\n",
      "   macro avg       1.00      1.00      1.00     35404\n",
      "weighted avg       1.00      1.00      1.00     35404\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y_train=classifier3.predict(X)\n",
    "# print confusion matrix-- training\n",
    "print(\"confusion matrix:\",confusion_matrix(yy, pred_y_train))\n",
    "print(\"other metrics:\",classification_report(yy, pred_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[9400   69   14]\n",
      " [ 184  129    5]\n",
      " [  28   19   16]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      9483\n",
      "           1       0.59      0.41      0.48       318\n",
      "           2       0.46      0.25      0.33        63\n",
      "\n",
      "    accuracy                           0.97      9864\n",
      "   macro avg       0.68      0.55      0.60      9864\n",
      "weighted avg       0.96      0.97      0.96      9864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix-- testing\n",
    "print(\"confusion matrix:\",confusion_matrix(y_test, pred_y_test))\n",
    "print(\"other metrics:\",classification_report(y_test, pred_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks like that downsampling the low-votes dramatically would make the distinctions between medium and low vague for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try do purely 2) down sampling for low votes events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample the low-votes\n",
    "df_0_downsampled = resample(class0,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(class1)*5, # match 5 times the medium class\n",
    "                                random_state = 12) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix all samples\n",
    "ndf=pd.concat([class2,class1,df_0_downsampled])\n",
    "# re-shuffle the order\n",
    "ndf=ndf.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the target classes, and then drop the votes from X data\n",
    "yy=get_class(ndf['votes'].values,80,300)\n",
    "ndf=ndf[usecolsX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the upsampled training data:\n",
      "number of low votes: 3705 ,compared with original: 31611\n",
      "number of medium votes: 741\n",
      "number of high votes: 147\n",
      "number of features in X: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"in the upsampled training data:\")\n",
    "print(\"number of low votes:\",list(yy).count(0),\",compared with original:\",list(y).count(0))\n",
    "print(\"number of medium votes:\",list(yy).count(1))\n",
    "print(\"number of high votes:\",list(yy).count(2))\n",
    "print(\"number of features in X:\",len(ndf.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale regression dataset\n",
    "scalar = MinMaxScaler()\n",
    "scalar.fit(ndf)\n",
    "X = scalar.transform(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4523283875696053\n"
     ]
    }
   ],
   "source": [
    "classifier4=RandomForestClassifier(n_estimators=90,random_state=12,max_features=int(max_f*.75),verbose=0)\n",
    "classifier4.fit(X,yy)\n",
    "pred_y_test=classifier4.predict(X_test)\n",
    "# assess the model performance: obtain prescision/recall/f1 scores\n",
    "a=precision_recall_fscore_support(y_test, pred_y_test)\n",
    "f1s=a[2]\n",
    "prec_rec+=[a[0]]\n",
    "recal_rec+=[a[1]]\n",
    "# create the weighted f1 score: larger emphasis on high-votes bin and medium\n",
    "# adjusted f1_forall= (f1_low+f1_mid*2+f1_high*3)/6\n",
    "adjf1=(f1s[0]+f1s[1]*2+f1s[2]*3)/6\n",
    "print(adjf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[3705    0    0]\n",
      " [   0  741    0]\n",
      " [   0    0  147]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3705\n",
      "           1       1.00      1.00      1.00       741\n",
      "           2       1.00      1.00      1.00       147\n",
      "\n",
      "    accuracy                           1.00      4593\n",
      "   macro avg       1.00      1.00      1.00      4593\n",
      "weighted avg       1.00      1.00      1.00      4593\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y_train=classifier4.predict(X)\n",
    "# print confusion matrix-- training\n",
    "print(\"confusion matrix:\",confusion_matrix(yy, pred_y_train))\n",
    "print(\"other metrics:\",classification_report(yy, pred_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[9172  294   17]\n",
      " [ 115  198    5]\n",
      " [  19   31   13]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98      9483\n",
      "           1       0.38      0.62      0.47       318\n",
      "           2       0.37      0.21      0.27        63\n",
      "\n",
      "    accuracy                           0.95      9864\n",
      "   macro avg       0.58      0.60      0.57      9864\n",
      "weighted avg       0.96      0.95      0.96      9864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix-- testing\n",
    "print(\"confusion matrix:\",confusion_matrix(y_test, pred_y_test))\n",
    "print(\"other metrics:\",classification_report(y_test, pred_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tone down the downsampling of low-votes : (to be 10 times the medium votes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample the low-votes\n",
    "df_0_downsampled = resample(class0,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = len(class1)*10, # match 5 times the medium class\n",
    "                                random_state = 12) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix all samples\n",
    "ndf=pd.concat([class2,class1,df_0_downsampled])\n",
    "# re-shuffle the order\n",
    "ndf=ndf.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the target classes, and then drop the votes from X data\n",
    "yy=get_class(ndf['votes'].values,80,300)\n",
    "ndf=ndf[usecolsX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the upsampled training data:\n",
      "number of low votes: 7410 ,compared with original: 31611\n",
      "number of medium votes: 741\n",
      "number of high votes: 147\n",
      "number of features in X: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"in the upsampled training data:\")\n",
    "print(\"number of low votes:\",list(yy).count(0),\",compared with original:\",list(y).count(0))\n",
    "print(\"number of medium votes:\",list(yy).count(1))\n",
    "print(\"number of high votes:\",list(yy).count(2))\n",
    "print(\"number of features in X:\",len(ndf.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale regression dataset\n",
    "scalar = MinMaxScaler()\n",
    "scalar.fit(ndf)\n",
    "X = scalar.transform(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4616830726320679\n"
     ]
    }
   ],
   "source": [
    "classifier5=RandomForestClassifier(n_estimators=90,random_state=12,max_features=int(max_f*.75),verbose=0)\n",
    "classifier5.fit(X,yy)\n",
    "pred_y_test=classifier5.predict(X_test)\n",
    "# assess the model performance: obtain prescision/recall/f1 scores\n",
    "a=precision_recall_fscore_support(y_test, pred_y_test)\n",
    "f1s=a[2]\n",
    "prec_rec+=[a[0]]\n",
    "recal_rec+=[a[1]]\n",
    "# create the weighted f1 score: larger emphasis on high-votes bin and medium\n",
    "# adjusted f1_forall= (f1_low+f1_mid*2+f1_high*3)/6\n",
    "adjf1=(f1s[0]+f1s[1]*2+f1s[2]*3)/6\n",
    "print(adjf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[7410    0    0]\n",
      " [   0  741    0]\n",
      " [   0    0  147]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      7410\n",
      "           1       1.00      1.00      1.00       741\n",
      "           2       1.00      1.00      1.00       147\n",
      "\n",
      "    accuracy                           1.00      8298\n",
      "   macro avg       1.00      1.00      1.00      8298\n",
      "weighted avg       1.00      1.00      1.00      8298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y_train=classifier5.predict(X)\n",
    "# print confusion matrix-- training\n",
    "print(\"confusion matrix:\",confusion_matrix(yy, pred_y_train))\n",
    "print(\"other metrics:\",classification_report(yy, pred_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[9331  141   11]\n",
      " [ 155  159    4]\n",
      " [  25   26   12]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      9483\n",
      "           1       0.49      0.50      0.49       318\n",
      "           2       0.44      0.19      0.27        63\n",
      "\n",
      "    accuracy                           0.96      9864\n",
      "   macro avg       0.64      0.56      0.58      9864\n",
      "weighted avg       0.96      0.96      0.96      9864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix-- testing\n",
    "print(\"confusion matrix:\",confusion_matrix(y_test, pred_y_test))\n",
    "print(\"other metrics:\",classification_report(y_test, pred_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 3) combining the upsample and down sampling : Test1 , low votes downsample 50% to original, medium votes upsample to 30% of low-votes, high votes upsample to be the original medium votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample the low-votes\n",
    "df_0_downsampled = resample(class0,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = int(len(class0)*.5), # use only 75% of the original \n",
    "                                random_state = 12) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample the mid-votes \n",
    "df_1_upsampled = resample(class1,\n",
    "                                replace = True, # sample with replacement\n",
    "                                n_samples = int(len(class0)*.30), # match 30% of the low class\n",
    "                                random_state = 12) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample the high-votes \n",
    "df_2_upsampled = resample(class2,\n",
    "                                replace = True, # sample with replacement\n",
    "                                n_samples = len(class1), # match the medium class\n",
    "                                random_state = 12) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix all samples\n",
    "ndf=pd.concat([df_1_upsampled,df_2_upsampled,df_0_downsampled])\n",
    "# re-shuffle the order\n",
    "ndf=ndf.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the target classes, and then drop the votes from X data\n",
    "yy=get_class(ndf['votes'].values,80,300)\n",
    "ndf=ndf[usecolsX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the upsampled training data:\n",
      "number of low votes: 11064 ,compared with original: 31611\n",
      "number of medium votes: 6638\n",
      "number of high votes: 741\n",
      "number of features in X: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"in the upsampled training data:\")\n",
    "print(\"number of low votes:\",list(yy).count(0),\",compared with original:\",list(y).count(0))\n",
    "print(\"number of medium votes:\",list(yy).count(1))\n",
    "print(\"number of high votes:\",list(yy).count(2))\n",
    "print(\"number of features in X:\",len(ndf.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decrease sample size on the percentage: -19.868786930830726 %\n"
     ]
    }
   ],
   "source": [
    "print(\"decrease sample size on the percentage:\",(len(ndf)-len(X_train))/len(X_train)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale regression dataset\n",
    "scalar = MinMaxScaler()\n",
    "scalar.fit(ndf)\n",
    "X = scalar.transform(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49979401037881965\n"
     ]
    }
   ],
   "source": [
    "classifier6=RandomForestClassifier(n_estimators=90,random_state=12,max_features=int(max_f*.75),verbose=0)\n",
    "classifier6.fit(X,yy)\n",
    "pred_y_test=classifier6.predict(X_test)\n",
    "# assess the model performance: obtain prescision/recall/f1 scores\n",
    "a=precision_recall_fscore_support(y_test, pred_y_test)\n",
    "f1s=a[2]\n",
    "prec_rec+=[a[0]]\n",
    "recal_rec+=[a[1]]\n",
    "# create the weighted f1 score: larger emphasis on high-votes bin and medium\n",
    "# adjusted f1_forall= (f1_low+f1_mid*2+f1_high*3)/6\n",
    "adjf1=(f1s[0]+f1s[1]*2+f1s[2]*3)/6\n",
    "print(adjf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[11063     1     0]\n",
      " [    0  6638     0]\n",
      " [    0     0   741]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     11064\n",
      "           1       1.00      1.00      1.00      6638\n",
      "           2       1.00      1.00      1.00       741\n",
      "\n",
      "    accuracy                           1.00     18443\n",
      "   macro avg       1.00      1.00      1.00     18443\n",
      "weighted avg       1.00      1.00      1.00     18443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y_train=classifier6.predict(X)\n",
    "# print confusion matrix-- training\n",
    "print(\"confusion matrix:\",confusion_matrix(yy, pred_y_train))\n",
    "print(\"other metrics:\",classification_report(yy, pred_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[9320  151   12]\n",
      " [ 155  154    9]\n",
      " [  25   20   18]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      9483\n",
      "           1       0.47      0.48      0.48       318\n",
      "           2       0.46      0.29      0.35        63\n",
      "\n",
      "    accuracy                           0.96      9864\n",
      "   macro avg       0.64      0.58      0.60      9864\n",
      "weighted avg       0.96      0.96      0.96      9864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix-- testing\n",
    "print(\"confusion matrix:\",confusion_matrix(y_test, pred_y_test))\n",
    "print(\"other metrics:\",classification_report(y_test, pred_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of the cat 0 and 1: 11434.5\n",
      "mean of the cat 1 and 2: 444.0\n",
      "mean of means: 5939.0\n"
     ]
    }
   ],
   "source": [
    "# get an average number from 3 groups\n",
    "print(\"mean of the cat 0 and 1:\",np.mean([list(y_train).count(0),list(y_train).count(1)]))\n",
    "print(\"mean of the cat 1 and 2:\",np.mean([list(y_train).count(1),list(y_train).count(2)]))\n",
    "print(\"mean of means:\",np.mean([11434,444]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 3) combining the upsample and down sampling : Test2 , use low votes downsample 50% to original, medium votes upsample to ~5 times of original, high votes upsample to be 2 times orginal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample the low-votes\n",
    "df_0_downsampled = resample(class0,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = 11434, # match the medium class\n",
    "                                random_state = 12) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample the mid-votes \n",
    "df_1_upsampled = resample(class1,\n",
    "                                replace = True, # sample with replacement\n",
    "                                n_samples = 5939, # match the medium class\n",
    "                                random_state = 12) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample the high-votes \n",
    "df_2_upsampled = resample(class2,\n",
    "                                replace = True, # sample with replacement\n",
    "                                n_samples = 444, # match the medium class\n",
    "                                random_state = 12) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix all samples\n",
    "ndf=pd.concat([df_2_upsampled,df_1_upsampled,df_0_downsampled])\n",
    "# re-shuffle the order\n",
    "ndf=ndf.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the target classes, and then drop the votes from X data\n",
    "yy=get_class(ndf['votes'].values,80,300)\n",
    "ndf=ndf[usecolsX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the upsampled training data:\n",
      "number of low votes: 11434 ,compared with original: 31611\n",
      "number of medium votes: 5939 ,compared with original: 1059\n",
      "number of high votes: 444 ,compared with original: 210\n",
      "number of features in X: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"in the upsampled training data:\")\n",
    "print(\"number of low votes:\",list(yy).count(0),\",compared with original:\",list(y).count(0))\n",
    "print(\"number of medium votes:\",list(yy).count(1),\",compared with original:\",list(y).count(1))\n",
    "print(\"number of high votes:\",list(yy).count(2),\",compared with original:\",list(y).count(2))\n",
    "print(\"number of features in X:\",len(ndf.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decrease sample size on the percentage: -22.588633993743482 %\n"
     ]
    }
   ],
   "source": [
    "print(\"decrease sample size on the percentage:\",(len(ndf)-len(X_train))/len(X_train)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale classifier dataset\n",
    "scalar = MinMaxScaler()\n",
    "scalar.fit(ndf)\n",
    "X = scalar.transform(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46608448780117406\n"
     ]
    }
   ],
   "source": [
    "classifier7=RandomForestClassifier(n_estimators=20,random_state=12,verbose=0)\n",
    "classifier7.fit(X,yy)\n",
    "pred_y_test=classifier7.predict(X_test)\n",
    "# assess the model performance: obtain prescision/recall/f1 scores\n",
    "a=precision_recall_fscore_support(y_test, pred_y_test)\n",
    "f1s=a[2]\n",
    "prec_rec+=[a[0]]\n",
    "recal_rec+=[a[1]]\n",
    "# create the weighted f1 score: larger emphasis on high-votes bin and medium\n",
    "# adjusted f1_forall= (f1_low+f1_mid*2+f1_high*3)/6\n",
    "adjf1=(f1s[0]+f1s[1]*2+f1s[2]*3)/6\n",
    "print(adjf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[11433     1     0]\n",
      " [    0  5939     0]\n",
      " [    0     1   443]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     11434\n",
      "           1       1.00      1.00      1.00      5939\n",
      "           2       1.00      1.00      1.00       444\n",
      "\n",
      "    accuracy                           1.00     17817\n",
      "   macro avg       1.00      1.00      1.00     17817\n",
      "weighted avg       1.00      1.00      1.00     17817\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y_train=classifier7.predict(X)\n",
    "# print confusion matrix-- training\n",
    "print(\"confusion matrix:\",confusion_matrix(yy, pred_y_train))\n",
    "print(\"other metrics:\",classification_report(yy, pred_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[9357  120    6]\n",
      " [ 158  157    3]\n",
      " [  30   22   11]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      9483\n",
      "           1       0.53      0.49      0.51       318\n",
      "           2       0.55      0.17      0.27        63\n",
      "\n",
      "    accuracy                           0.97      9864\n",
      "   macro avg       0.69      0.55      0.59      9864\n",
      "weighted avg       0.96      0.97      0.96      9864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix-- testing\n",
    "print(\"confusion matrix:\",confusion_matrix(y_test, pred_y_test))\n",
    "print(\"other metrics:\",classification_report(y_test, pred_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.97489669, 0.65432099, 0.63636364]),\n",
       " array([0.97458678, 0.66896552, 0.53846154]),\n",
       " array([0.97856177, 0.59545455, 0.45714286]),\n",
       " array([0.97794653, 0.58256881, 0.48484848]),\n",
       " array([0.97794424, 0.59447005, 0.45714286]),\n",
       " array([0.98560069, 0.37858509, 0.37142857]),\n",
       " array([0.98107455, 0.48773006, 0.44444444]),\n",
       " array([0.98115591, 0.4689441 , 0.39534884]),\n",
       " array([0.98030382, 0.52508361, 0.55      ])]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_prec=[x[2] for x in prec_rec]\n",
    "high_recal=[x[2] for x in recal_rec]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1bdce5b3da0>"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the final results\n",
    "\n",
    "# set up matplot figure\n",
    "fig =plt.figure(figsize=(20,10))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax1.title.set_text('precision-recall')\n",
    "ax1.set_xlim([0,1.05])\n",
    "ax1.set_ylim([0,1.05])\n",
    "ax2.title.set_text('Weighted F1 score')\n",
    "# preset color scale\n",
    "NUM_COLORS = 9\n",
    "colors = cm.rainbow(np.linspace(0, 1, NUM_COLORS))\n",
    "ct=0# counter for colors\n",
    "\n",
    "ax1.scatter(high_prec,high_recal,color=colors)\n",
    "ax2.scatter([1,2,3,4,5,6,7,8,9],[0.476,0.5096,0.4898,0.4887,0.4881,0.4523,0.4617,0.4998,0.4661],color=colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try 4) SMOTE upsample the high-votes: extreme, upsample the high votes to same value of medium votes with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE \n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = SMOTE().fit_resample(X_train.iloc[:,0:25], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 22128), (1, 22128), (2, 22128)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale regression dataset\n",
    "scalar = MinMaxScaler()\n",
    "scalar.fit(X_resampled)\n",
    "X = scalar.transform(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48389815194237656\n"
     ]
    }
   ],
   "source": [
    "classifier8=RandomForestClassifier(n_estimators=90,random_state=12,max_features=int(max_f*.75),verbose=0)\n",
    "classifier8.fit(X,y_resampled)\n",
    "pred_y_test=classifier8.predict(X_test)\n",
    "# assess the model performance: obtain prescision/recall/f1 scores\n",
    "a=precision_recall_fscore_support(y_test, pred_y_test)\n",
    "f1s=a[2]\n",
    "prec_rec+=[a[0]]\n",
    "recal_rec+=[a[1]]\n",
    "# create the weighted f1 score: larger emphasis on high-votes bin and medium\n",
    "# adjusted f1_forall= (f1_low+f1_mid*2+f1_high*3)/6\n",
    "adjf1=(f1s[0]+f1s[1]*2+f1s[2]*3)/6\n",
    "print(adjf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[22127     1     0]\n",
      " [    0 22128     0]\n",
      " [    0     0 22128]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     22128\n",
      "           1       1.00      1.00      1.00     22128\n",
      "           2       1.00      1.00      1.00     22128\n",
      "\n",
      "    accuracy                           1.00     66384\n",
      "   macro avg       1.00      1.00      1.00     66384\n",
      "weighted avg       1.00      1.00      1.00     66384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y_train=classifier8.predict(X)\n",
    "# print confusion matrix-- training\n",
    "print(\"confusion matrix:\",confusion_matrix(y_resampled, pred_y_train))\n",
    "print(\"other metrics:\",classification_report(y_resampled, pred_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[9341  124   18]\n",
      " [ 161  148    9]\n",
      " [  24   22   17]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      9483\n",
      "           1       0.50      0.47      0.48       318\n",
      "           2       0.39      0.27      0.32        63\n",
      "\n",
      "    accuracy                           0.96      9864\n",
      "   macro avg       0.62      0.57      0.59      9864\n",
      "weighted avg       0.96      0.96      0.96      9864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix-- testing\n",
    "print(\"confusion matrix:\",confusion_matrix(y_test, pred_y_test))\n",
    "print(\"other metrics:\",classification_report(y_test, pred_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Same upsampling from random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample the mid-votes \n",
    "df_1_upsampled = resample(class1,\n",
    "                                replace = True, # sample with replacement\n",
    "                                n_samples = int(len(class0)), # match 30% of the low class\n",
    "                                random_state = 12) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upsample the high-votes \n",
    "df_2_upsampled = resample(class2,\n",
    "                                replace = True, # sample with replacement\n",
    "                                n_samples = len(class0), # match the medium class\n",
    "                                random_state = 12) # reproducible results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix all samples\n",
    "ndf=pd.concat([df_2_upsampled,df_1_upsampled,class0])\n",
    "# re-shuffle the order\n",
    "ndf=ndf.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the target classes, and then drop the votes from X data\n",
    "yy=get_class(ndf['votes'].values,80,300)\n",
    "ndf=ndf[usecolsX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the upsampled training data:\n",
      "number of low votes: 22128 ,compared with original: 31611\n",
      "number of medium votes: 22128 ,compared with original: 1059\n",
      "number of high votes: 22128 ,compared with original: 210\n",
      "number of features in X: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"in the upsampled training data:\")\n",
    "print(\"number of low votes:\",list(yy).count(0))\n",
    "print(\"number of medium votes:\",list(yy).count(1),\",compared with original:\",list(y).count(1))\n",
    "print(\"number of high votes:\",list(yy).count(2),\",compared with original:\",list(y).count(2))\n",
    "print(\"number of features in X:\",len(ndf.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "increase sample size on the percentage: 188.42544316996873 %\n"
     ]
    }
   ],
   "source": [
    "print(\"increase sample size on the percentage:\",(len(ndf)-len(X_train))/len(X_train)*100,\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale regression dataset\n",
    "scalar = MinMaxScaler()\n",
    "scalar.fit(ndf)\n",
    "X = scalar.transform(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4828428005877874\n"
     ]
    }
   ],
   "source": [
    "classifier8=RandomForestClassifier(n_estimators=20,random_state=12,verbose=0)\n",
    "classifier8.fit(X,yy)\n",
    "pred_y_test=classifier8.predict(X_test)\n",
    "# assess the model performance: obtain prescision/recall/f1 scores\n",
    "a=precision_recall_fscore_support(y_test, pred_y_test)\n",
    "f1s=a[2]\n",
    "prec_rec+=[a[0]]\n",
    "recal_rec+=[a[1]]\n",
    "# create the weighted f1 score: larger emphasis on high-votes bin and medium\n",
    "# adjusted f1_forall= (f1_low+f1_mid*2+f1_high*3)/6\n",
    "adjf1=(f1s[0]+f1s[1]*2+f1s[2]*3)/6\n",
    "print(adjf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[22126     2     0]\n",
      " [    0 22128     0]\n",
      " [    0     0 22128]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     22128\n",
      "           1       1.00      1.00      1.00     22128\n",
      "           2       1.00      1.00      1.00     22128\n",
      "\n",
      "    accuracy                           1.00     66384\n",
      "   macro avg       1.00      1.00      1.00     66384\n",
      "weighted avg       1.00      1.00      1.00     66384\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y_train=classifier8.predict(X)\n",
    "# print confusion matrix-- training\n",
    "print(\"confusion matrix:\",confusion_matrix(yy, pred_y_train))\n",
    "print(\"other metrics:\",classification_report(yy, pred_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[9427   49    7]\n",
      " [ 192  118    8]\n",
      " [  33   15   15]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      9483\n",
      "           1       0.65      0.37      0.47       318\n",
      "           2       0.50      0.24      0.32        63\n",
      "\n",
      "    accuracy                           0.97      9864\n",
      "   macro avg       0.71      0.53      0.59      9864\n",
      "weighted avg       0.96      0.97      0.96      9864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix-- testing\n",
    "print(\"confusion matrix:\",confusion_matrix(y_test, pred_y_test))\n",
    "print(\"other metrics:\",classification_report(y_test, pred_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE upsampling is slightly better"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try ADASYN upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = ADASYN().fit_resample(X_train.iloc[:,0:25], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 22128), (1, 22207), (2, 22155)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale regression dataset\n",
    "scalar = MinMaxScaler()\n",
    "scalar.fit(X_resampled)\n",
    "X = scalar.transform(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46969548577127157\n"
     ]
    }
   ],
   "source": [
    "classifier9=RandomForestClassifier(n_estimators=90,random_state=12,max_features=int(max_f*.75),verbose=0)\n",
    "classifier9.fit(X,y_resampled)\n",
    "pred_y_test=classifier9.predict(X_test)\n",
    "# assess the model performance: obtain prescision/recall/f1 scores\n",
    "a=precision_recall_fscore_support(y_test, pred_y_test)\n",
    "f1s=a[2]\n",
    "prec_rec+=[a[0]]\n",
    "recal_rec+=[a[1]]\n",
    "# create the weighted f1 score: larger emphasis on high-votes bin and medium\n",
    "# adjusted f1_forall= (f1_low+f1_mid*2+f1_high*3)/6\n",
    "adjf1=(f1s[0]+f1s[1]*2+f1s[2]*3)/6\n",
    "print(adjf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[22127     1     0]\n",
      " [    0 22207     0]\n",
      " [    0     0 22155]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     22128\n",
      "           1       1.00      1.00      1.00     22207\n",
      "           2       1.00      1.00      1.00     22155\n",
      "\n",
      "    accuracy                           1.00     66490\n",
      "   macro avg       1.00      1.00      1.00     66490\n",
      "weighted avg       1.00      1.00      1.00     66490\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred_y_train=classifier9.predict(X)\n",
    "# print confusion matrix-- training\n",
    "print(\"confusion matrix:\",confusion_matrix(y_resampled, pred_y_train))\n",
    "print(\"other metrics:\",classification_report(y_resampled, pred_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[9330  133   20]\n",
      " [ 157  150   11]\n",
      " [  25   22   16]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      9483\n",
      "           1       0.49      0.47      0.48       318\n",
      "           2       0.34      0.25      0.29        63\n",
      "\n",
      "    accuracy                           0.96      9864\n",
      "   macro avg       0.60      0.57      0.58      9864\n",
      "weighted avg       0.96      0.96      0.96      9864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix-- testing\n",
    "print(\"confusion matrix:\",confusion_matrix(y_test, pred_y_test))\n",
    "print(\"other metrics:\",classification_report(y_test, pred_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test combining downsampling low-votes and then SMOTE the medium and high votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11064 22128\n"
     ]
    }
   ],
   "source": [
    "# downsample the low-votes\n",
    "df_0_downsampled = resample(class0,\n",
    "                                replace = False, # sample without replacement\n",
    "                                n_samples = int(len(class0)*.5), # match the medium class\n",
    "                                random_state = 12) # reproducible results\n",
    "print(len(df_0_downsampled),len(class0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix all samples\n",
    "ndf=pd.concat([class1,class2,df_0_downsampled])\n",
    "# re-shuffle the order\n",
    "ndf=ndf.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the target classes, and then drop the votes from X data\n",
    "yy=get_class(ndf['votes'].values,80,300)\n",
    "ndf=ndf[usecolsX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the upsampled training data:\n",
      "number of low votes: 11064 ,compared with original: 22128\n",
      "number of medium votes: 741\n",
      "number of high votes: 147\n",
      "number of features in X: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"in the upsampled training data:\")\n",
    "print(\"number of low votes:\",list(yy).count(0),\",compared with original:\",list(y_train).count(0))\n",
    "print(\"number of medium votes:\",list(yy).count(1))\n",
    "print(\"number of high votes:\",list(yy).count(2))\n",
    "print(\"number of features in X:\",len(ndf.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale the features:\n",
    "scalar = MinMaxScaler()\n",
    "scalar.fit(ndf)\n",
    "X = scalar.transform(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = SMOTE().fit_resample(X, yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the upsampled/downsample training data:\n",
      "number of low votes: 11064 ,compared with original: 22128\n",
      "number of medium votes: 11064 ,compared with original: 741\n",
      "number of high votes: 11064 ,compared with original: 147\n",
      "number of features in X: 25\n"
     ]
    }
   ],
   "source": [
    "# rescale the features:\n",
    "scalar = MinMaxScaler()\n",
    "scalar.fit(ndf)\n",
    "X = scalar.transform(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45013124323262693\n"
     ]
    }
   ],
   "source": [
    "classifier9=RandomForestClassifier(n_estimators=90,random_state=12,max_features=int(max_f*.75),verbose=0)\n",
    "classifier9.fit(X_resampled,y_resampled)\n",
    "pred_y_test=classifier9.predict(X_test)\n",
    "# assess the model performance: obtain prescision/recall/f1 scores\n",
    "a=precision_recall_fscore_support(y_test, pred_y_test)\n",
    "f1s=a[2]\n",
    "prec_rec+=[a[0]]\n",
    "recal_rec+=[a[1]]\n",
    "# create the weighted f1 score: larger emphasis on high-votes bin and medium\n",
    "# adjusted f1_forall= (f1_low+f1_mid*2+f1_high*3)/6\n",
    "adjf1=(f1s[0]+f1s[1]*2+f1s[2]*3)/6\n",
    "print(adjf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[9043  375   65]\n",
      " [  99  206   13]\n",
      " [  12   28   23]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97      9483\n",
      "           1       0.34      0.65      0.44       318\n",
      "           2       0.23      0.37      0.28        63\n",
      "\n",
      "    accuracy                           0.94      9864\n",
      "   macro avg       0.52      0.66      0.57      9864\n",
      "weighted avg       0.96      0.94      0.95      9864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix-- testing\n",
    "print(\"confusion matrix:\",confusion_matrix(y_test, pred_y_test))\n",
    "print(\"other metrics:\",classification_report(y_test, pred_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test combining downsampling low-votes less aggressively (75%)and then SMOTE the medium and high votes: Less aggressive low-votes downsampling and then SMOTE medium and high to 50% of the number of low-votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16596\n"
     ]
    }
   ],
   "source": [
    "# downsample the low-votes\n",
    "df_0_downsampled = resample(class0,\n",
    "                            replace = False, # sample without replacement\n",
    "                            n_samples = int(len(class0)*.75), # downsample to 75% original\n",
    "                            random_state = 12) # reproducible results\n",
    "print(len(df_0_downsampled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample 75% of the low-votes\n",
    "n=int(len(df_0_downsampled)*.5)\n",
    "df_0_downsub = df_0_downsampled[:n]\n",
    "df_0_rest = df_0_downsampled[n+1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the 75% of the low votes and the mid/high\n",
    "ndf=pd.concat([class1,class2,df_0_downsub])\n",
    "# re-shuffle the order\n",
    "ndf=ndf.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the classes for the part that going into SMOTE\n",
    "yyy= get_class(ndf['votes'].values,80,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE the mid and low\n",
    "X_resampled, y_resampled = SMOTE().fit_resample(ndf,yyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 8298), (1, 8298), (2, 8298)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(Counter(y_resampled).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0_tol = pd.DataFrame(X_resampled, columns=usecolsX+['votes'])\n",
    "# add back the dataframes and reshuffle\n",
    "ndf=pd.concat([df_0_tol,df_0_rest])\n",
    "ndf=ndf.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "yy=get_class(ndf['votes'].values,80,300)\n",
    "ndf=ndf[usecolsX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale the features:\n",
    "scalar = MinMaxScaler()\n",
    "scalar.fit(ndf)\n",
    "X = scalar.transform(ndf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the upsampled training data:\n",
      "number of low votes: 16595 ,compared with original: 22128\n",
      "number of medium votes: 8298 741\n",
      "number of high votes: 8298 147\n",
      "number of features in X: 25\n"
     ]
    }
   ],
   "source": [
    "print(\"in the upsampled training data:\")\n",
    "print(\"number of low votes:\",list(yy).count(0),\",compared with original:\",list(y_train).count(0))\n",
    "print(\"number of medium votes:\",list(yy).count(1),list(y_train).count(1))\n",
    "print(\"number of high votes:\",list(yy).count(2),list(y_train).count(2))\n",
    "print(\"number of features in X:\",len(ndf.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.47403047137725024\n"
     ]
    }
   ],
   "source": [
    "classifier10=RandomForestClassifier(n_estimators=90,random_state=12,max_features=int(max_f*.75),verbose=0)\n",
    "classifier10.fit(X,yy)\n",
    "pred_y_test=classifier10.predict(X_test)\n",
    "# assess the model performance: obtain prescision/recall/f1 scores\n",
    "a=precision_recall_fscore_support(y_test, pred_y_test)\n",
    "f1s=a[2]\n",
    "prec_rec+=[a[0]]\n",
    "recal_rec+=[a[1]]\n",
    "# create the weighted f1 score: larger emphasis on high-votes bin and medium\n",
    "# adjusted f1_forall= (f1_low+f1_mid*2+f1_high*3)/6\n",
    "adjf1=(f1s[0]+f1s[1]*2+f1s[2]*3)/6\n",
    "print(adjf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[9333  129   21]\n",
      " [ 156  153    9]\n",
      " [  23   24   16]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98      9483\n",
      "           1       0.50      0.48      0.49       318\n",
      "           2       0.35      0.25      0.29        63\n",
      "\n",
      "    accuracy                           0.96      9864\n",
      "   macro avg       0.61      0.57      0.59      9864\n",
      "weighted avg       0.96      0.96      0.96      9864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix-- testing\n",
    "print(\"confusion matrix:\",confusion_matrix(y_test, pred_y_test))\n",
    "print(\"other metrics:\",classification_report(y_test, pred_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "# Try the Neural network model with up/down sample dataset\n",
    "# formulate y data (specifically required by NN model)\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(yy)\n",
    "encoded_Y = encoder.transform(yy)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfeature=X.shape[1]\n",
    "Nmodel=Sequential()\n",
    "Nmodel.add(Dense(nfeature+5,input_dim=nfeature, activation='relu'))\n",
    "#Nmodel.add(Dense(nfeature+5, activation='relu'))\n",
    "#Nmodel.add(Dense(nfeature, activation='relu'))\n",
    "Nmodel.add(Dense(nfeature-5, activation='relu'))\n",
    "Nmodel.add(Dense(3, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[f1_m,precision_m, recall_m])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 1.1798 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+0 - ETA: 0s - loss: 0.9650 - f1_m: 0.3439 - precision_m: 0.5979 - recall_m: 0.2595            - ETA: 0s - loss: 0.8918 - f1_m: 0.4676 - precision_m: 0.6704 - recall_m: 0.378 - ETA: 0s - loss: 0.8445 - f1_m: 0.5241 - precision_m: 0.7013 - recall_m: 0.435 - ETA: 0s - loss: 0.8114 - f1_m: 0.5611 - precision_m: 0.7176 - recall_m: 0.476 - ETA: 0s - loss: 0.7874 - f1_m: 0.5856 - precision_m: 0.7277 - recall_m: 0.505 - ETA: 0s - loss: 0.7697 - f1_m: 0.6026 - precision_m: 0.7347 - recall_m: 0.524 - 0s 10us/step - loss: 0.7594 - f1_m: 0.6114 - precision_m: 0.7389 - recall_m: 0.5349\n",
      "Epoch 2/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.8374 - f1_m: 0.6296 - precision_m: 0.7727 - recall_m: 0.531 - ETA: 0s - loss: 0.6292 - f1_m: 0.7191 - precision_m: 0.7876 - recall_m: 0.663 - ETA: 0s - loss: 0.6201 - f1_m: 0.7233 - precision_m: 0.7878 - recall_m: 0.670 - ETA: 0s - loss: 0.6125 - f1_m: 0.7272 - precision_m: 0.7892 - recall_m: 0.675 - ETA: 0s - loss: 0.6064 - f1_m: 0.7317 - precision_m: 0.7922 - recall_m: 0.681 - ETA: 0s - loss: 0.6017 - f1_m: 0.7359 - precision_m: 0.7943 - recall_m: 0.687 - ETA: 0s - loss: 0.5941 - f1_m: 0.7404 - precision_m: 0.7974 - recall_m: 0.692 - 0s 11us/step - loss: 0.5904 - f1_m: 0.7428 - precision_m: 0.7982 - recall_m: 0.6963\n",
      "Epoch 3/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.5741 - f1_m: 0.7541 - precision_m: 0.7931 - recall_m: 0.718 - ETA: 0s - loss: 0.5477 - f1_m: 0.7707 - precision_m: 0.8125 - recall_m: 0.734 - ETA: 0s - loss: 0.5455 - f1_m: 0.7719 - precision_m: 0.8127 - recall_m: 0.736 - ETA: 0s - loss: 0.5375 - f1_m: 0.7767 - precision_m: 0.8171 - recall_m: 0.741 - ETA: 0s - loss: 0.5305 - f1_m: 0.7788 - precision_m: 0.8185 - recall_m: 0.744 - ETA: 0s - loss: 0.5289 - f1_m: 0.7783 - precision_m: 0.8177 - recall_m: 0.743 - ETA: 0s - loss: 0.5267 - f1_m: 0.7788 - precision_m: 0.8172 - recall_m: 0.745 - 0s 10us/step - loss: 0.5230 - f1_m: 0.7805 - precision_m: 0.8183 - recall_m: 0.7472\n",
      "Epoch 4/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.4488 - f1_m: 0.8065 - precision_m: 0.8333 - recall_m: 0.781 - ETA: 0s - loss: 0.4980 - f1_m: 0.7946 - precision_m: 0.8261 - recall_m: 0.766 - ETA: 0s - loss: 0.4987 - f1_m: 0.7928 - precision_m: 0.8266 - recall_m: 0.762 - ETA: 0s - loss: 0.4935 - f1_m: 0.7953 - precision_m: 0.8268 - recall_m: 0.767 - ETA: 0s - loss: 0.4878 - f1_m: 0.7976 - precision_m: 0.8288 - recall_m: 0.769 - ETA: 0s - loss: 0.4817 - f1_m: 0.8005 - precision_m: 0.8307 - recall_m: 0.773 - ETA: 0s - loss: 0.4823 - f1_m: 0.8006 - precision_m: 0.8305 - recall_m: 0.773 - 0s 10us/step - loss: 0.4794 - f1_m: 0.8020 - precision_m: 0.8317 - recall_m: 0.7752\n",
      "Epoch 5/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.4214 - f1_m: 0.8710 - precision_m: 0.9000 - recall_m: 0.843 - ETA: 0s - loss: 0.4471 - f1_m: 0.8152 - precision_m: 0.8409 - recall_m: 0.791 - ETA: 0s - loss: 0.4478 - f1_m: 0.8176 - precision_m: 0.8420 - recall_m: 0.795 - ETA: 0s - loss: 0.4484 - f1_m: 0.8202 - precision_m: 0.8450 - recall_m: 0.797 - ETA: 0s - loss: 0.4451 - f1_m: 0.8219 - precision_m: 0.8467 - recall_m: 0.799 - ETA: 0s - loss: 0.4457 - f1_m: 0.8207 - precision_m: 0.8451 - recall_m: 0.798 - ETA: 0s - loss: 0.4450 - f1_m: 0.8209 - precision_m: 0.8450 - recall_m: 0.798 - 0s 11us/step - loss: 0.4440 - f1_m: 0.8213 - precision_m: 0.8450 - recall_m: 0.7996\n",
      "Epoch 6/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.4073 - f1_m: 0.8525 - precision_m: 0.8966 - recall_m: 0.812 - ETA: 0s - loss: 0.4201 - f1_m: 0.8324 - precision_m: 0.8534 - recall_m: 0.813 - ETA: 0s - loss: 0.4250 - f1_m: 0.8291 - precision_m: 0.8497 - recall_m: 0.810 - ETA: 0s - loss: 0.4277 - f1_m: 0.8279 - precision_m: 0.8486 - recall_m: 0.808 - ETA: 0s - loss: 0.4244 - f1_m: 0.8290 - precision_m: 0.8500 - recall_m: 0.809 - ETA: 0s - loss: 0.4213 - f1_m: 0.8303 - precision_m: 0.8508 - recall_m: 0.811 - ETA: 0s - loss: 0.4187 - f1_m: 0.8321 - precision_m: 0.8521 - recall_m: 0.813 - 0s 11us/step - loss: 0.4151 - f1_m: 0.8334 - precision_m: 0.8532 - recall_m: 0.8152\n",
      "Epoch 7/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.6241 - f1_m: 0.7500 - precision_m: 0.7500 - recall_m: 0.750 - ETA: 0s - loss: 0.3940 - f1_m: 0.8442 - precision_m: 0.8610 - recall_m: 0.828 - ETA: 0s - loss: 0.3969 - f1_m: 0.8426 - precision_m: 0.8598 - recall_m: 0.826 - ETA: 0s - loss: 0.4006 - f1_m: 0.8419 - precision_m: 0.8585 - recall_m: 0.826 - ETA: 0s - loss: 0.4011 - f1_m: 0.8428 - precision_m: 0.8597 - recall_m: 0.827 - ETA: 0s - loss: 0.3993 - f1_m: 0.8431 - precision_m: 0.8598 - recall_m: 0.827 - ETA: 0s - loss: 0.3979 - f1_m: 0.8428 - precision_m: 0.8595 - recall_m: 0.827 - ETA: 0s - loss: 0.3971 - f1_m: 0.8435 - precision_m: 0.8601 - recall_m: 0.828 - ETA: 0s - loss: 0.3949 - f1_m: 0.8440 - precision_m: 0.8605 - recall_m: 0.828 - 0s 12us/step - loss: 0.3950 - f1_m: 0.8439 - precision_m: 0.8604 - recall_m: 0.8285\n",
      "Epoch 8/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.2965 - f1_m: 0.9206 - precision_m: 0.9355 - recall_m: 0.906 - ETA: 0s - loss: 0.3859 - f1_m: 0.8488 - precision_m: 0.8616 - recall_m: 0.836 - ETA: 0s - loss: 0.3829 - f1_m: 0.8470 - precision_m: 0.8618 - recall_m: 0.833 - ETA: 0s - loss: 0.3845 - f1_m: 0.8471 - precision_m: 0.8622 - recall_m: 0.833 - ETA: 0s - loss: 0.3827 - f1_m: 0.8475 - precision_m: 0.8622 - recall_m: 0.833 - ETA: 0s - loss: 0.3803 - f1_m: 0.8486 - precision_m: 0.8634 - recall_m: 0.834 - ETA: 0s - loss: 0.3799 - f1_m: 0.8480 - precision_m: 0.8628 - recall_m: 0.834 - ETA: 0s - loss: 0.3782 - f1_m: 0.8495 - precision_m: 0.8639 - recall_m: 0.836 - 0s 12us/step - loss: 0.3776 - f1_m: 0.8500 - precision_m: 0.8646 - recall_m: 0.8363\n",
      "Epoch 9/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.3386 - f1_m: 0.9375 - precision_m: 0.9375 - recall_m: 0.937 - ETA: 0s - loss: 0.3589 - f1_m: 0.8587 - precision_m: 0.8728 - recall_m: 0.845 - ETA: 0s - loss: 0.3629 - f1_m: 0.8568 - precision_m: 0.8719 - recall_m: 0.842 - ETA: 0s - loss: 0.3658 - f1_m: 0.8548 - precision_m: 0.8688 - recall_m: 0.841 - ETA: 0s - loss: 0.3637 - f1_m: 0.8566 - precision_m: 0.8704 - recall_m: 0.843 - ETA: 0s - loss: 0.3652 - f1_m: 0.8560 - precision_m: 0.8693 - recall_m: 0.843 - ETA: 0s - loss: 0.3647 - f1_m: 0.8563 - precision_m: 0.8699 - recall_m: 0.843 - 0s 10us/step - loss: 0.3657 - f1_m: 0.8558 - precision_m: 0.8695 - recall_m: 0.8429\n",
      "Epoch 10/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.3781 - f1_m: 0.8710 - precision_m: 0.9000 - recall_m: 0.843 - ETA: 0s - loss: 0.3605 - f1_m: 0.8597 - precision_m: 0.8728 - recall_m: 0.847 - ETA: 0s - loss: 0.3582 - f1_m: 0.8590 - precision_m: 0.8708 - recall_m: 0.847 - ETA: 0s - loss: 0.3569 - f1_m: 0.8597 - precision_m: 0.8722 - recall_m: 0.848 - ETA: 0s - loss: 0.3577 - f1_m: 0.8595 - precision_m: 0.8719 - recall_m: 0.847 - ETA: 0s - loss: 0.3554 - f1_m: 0.8611 - precision_m: 0.8734 - recall_m: 0.849 - ETA: 0s - loss: 0.3553 - f1_m: 0.8610 - precision_m: 0.8734 - recall_m: 0.849 - ETA: 0s - loss: 0.3543 - f1_m: 0.8615 - precision_m: 0.8739 - recall_m: 0.849 - 0s 12us/step - loss: 0.3542 - f1_m: 0.8610 - precision_m: 0.8733 - recall_m: 0.8493\n",
      "Epoch 11/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.1909 - f1_m: 0.9677 - precision_m: 1.0000 - recall_m: 0.937 - ETA: 0s - loss: 0.3406 - f1_m: 0.8651 - precision_m: 0.8756 - recall_m: 0.855 - ETA: 0s - loss: 0.3388 - f1_m: 0.8659 - precision_m: 0.8767 - recall_m: 0.855 - ETA: 0s - loss: 0.3423 - f1_m: 0.8646 - precision_m: 0.8762 - recall_m: 0.853 - ETA: 0s - loss: 0.3421 - f1_m: 0.8645 - precision_m: 0.8760 - recall_m: 0.853 - ETA: 0s - loss: 0.3410 - f1_m: 0.8642 - precision_m: 0.8753 - recall_m: 0.853 - ETA: 0s - loss: 0.3447 - f1_m: 0.8627 - precision_m: 0.8738 - recall_m: 0.852 - ETA: 0s - loss: 0.3450 - f1_m: 0.8631 - precision_m: 0.8742 - recall_m: 0.852 - ETA: 0s - loss: 0.3444 - f1_m: 0.8636 - precision_m: 0.8751 - recall_m: 0.852 - 0s 13us/step - loss: 0.3443 - f1_m: 0.8633 - precision_m: 0.8748 - recall_m: 0.8526\n",
      "Epoch 12/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.2981 - f1_m: 0.8437 - precision_m: 0.8438 - recall_m: 0.843 - ETA: 0s - loss: 0.3482 - f1_m: 0.8589 - precision_m: 0.8708 - recall_m: 0.847 - ETA: 0s - loss: 0.3514 - f1_m: 0.8575 - precision_m: 0.8693 - recall_m: 0.846 - ETA: 0s - loss: 0.3458 - f1_m: 0.8607 - precision_m: 0.8715 - recall_m: 0.850 - ETA: 0s - loss: 0.3393 - f1_m: 0.8646 - precision_m: 0.8752 - recall_m: 0.854 - ETA: 0s - loss: 0.3401 - f1_m: 0.8644 - precision_m: 0.8751 - recall_m: 0.854 - ETA: 0s - loss: 0.3378 - f1_m: 0.8659 - precision_m: 0.8764 - recall_m: 0.856 - ETA: 0s - loss: 0.3366 - f1_m: 0.8669 - precision_m: 0.8776 - recall_m: 0.856 - 0s 11us/step - loss: 0.3359 - f1_m: 0.8676 - precision_m: 0.8783 - recall_m: 0.8576\n",
      "Epoch 13/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.4480 - f1_m: 0.7937 - precision_m: 0.8065 - recall_m: 0.781 - ETA: 0s - loss: 0.3403 - f1_m: 0.8684 - precision_m: 0.8807 - recall_m: 0.856 - ETA: 0s - loss: 0.3346 - f1_m: 0.8700 - precision_m: 0.8810 - recall_m: 0.859 - ETA: 0s - loss: 0.3318 - f1_m: 0.8707 - precision_m: 0.8812 - recall_m: 0.860 - ETA: 0s - loss: 0.3278 - f1_m: 0.8710 - precision_m: 0.8813 - recall_m: 0.861 - ETA: 0s - loss: 0.3247 - f1_m: 0.8731 - precision_m: 0.8831 - recall_m: 0.863 - ETA: 0s - loss: 0.3275 - f1_m: 0.8718 - precision_m: 0.8819 - recall_m: 0.862 - 0s 10us/step - loss: 0.3270 - f1_m: 0.8718 - precision_m: 0.8818 - recall_m: 0.8623\n",
      "Epoch 14/50\n",
      "33191/33191 [==============================] - ETA: 3s - loss: 0.2472 - f1_m: 0.8889 - precision_m: 0.9032 - recall_m: 0.875 - ETA: 0s - loss: 0.3153 - f1_m: 0.8745 - precision_m: 0.8824 - recall_m: 0.866 - ETA: 0s - loss: 0.3258 - f1_m: 0.8711 - precision_m: 0.8801 - recall_m: 0.862 - ETA: 0s - loss: 0.3276 - f1_m: 0.8715 - precision_m: 0.8812 - recall_m: 0.862 - ETA: 0s - loss: 0.3233 - f1_m: 0.8746 - precision_m: 0.8840 - recall_m: 0.865 - ETA: 0s - loss: 0.3229 - f1_m: 0.8749 - precision_m: 0.8840 - recall_m: 0.866 - ETA: 0s - loss: 0.3226 - f1_m: 0.8743 - precision_m: 0.8833 - recall_m: 0.865 - 0s 10us/step - loss: 0.3217 - f1_m: 0.8747 - precision_m: 0.8838 - recall_m: 0.8660\n",
      "Epoch 15/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.1734 - f1_m: 0.9524 - precision_m: 0.9677 - recall_m: 0.937 - ETA: 0s - loss: 0.3147 - f1_m: 0.8792 - precision_m: 0.8878 - recall_m: 0.871 - ETA: 0s - loss: 0.3149 - f1_m: 0.8776 - precision_m: 0.8856 - recall_m: 0.869 - ETA: 0s - loss: 0.3180 - f1_m: 0.8765 - precision_m: 0.8844 - recall_m: 0.869 - ETA: 0s - loss: 0.3168 - f1_m: 0.8774 - precision_m: 0.8854 - recall_m: 0.869 - ETA: 0s - loss: 0.3169 - f1_m: 0.8775 - precision_m: 0.8856 - recall_m: 0.869 - ETA: 0s - loss: 0.3137 - f1_m: 0.8785 - precision_m: 0.8867 - recall_m: 0.870 - 0s 10us/step - loss: 0.3150 - f1_m: 0.8781 - precision_m: 0.8864 - recall_m: 0.8701\n",
      "Epoch 16/50\n",
      "33191/33191 [==============================] - ETA: 3s - loss: 0.3780 - f1_m: 0.8065 - precision_m: 0.8333 - recall_m: 0.781 - ETA: 0s - loss: 0.3011 - f1_m: 0.8834 - precision_m: 0.8917 - recall_m: 0.875 - ETA: 0s - loss: 0.3136 - f1_m: 0.8795 - precision_m: 0.8877 - recall_m: 0.871 - ETA: 0s - loss: 0.3109 - f1_m: 0.8794 - precision_m: 0.8881 - recall_m: 0.871 - ETA: 0s - loss: 0.3083 - f1_m: 0.8802 - precision_m: 0.8886 - recall_m: 0.872 - ETA: 0s - loss: 0.3058 - f1_m: 0.8812 - precision_m: 0.8892 - recall_m: 0.873 - ETA: 0s - loss: 0.3050 - f1_m: 0.8819 - precision_m: 0.8899 - recall_m: 0.874 - 0s 10us/step - loss: 0.3057 - f1_m: 0.8811 - precision_m: 0.8891 - recall_m: 0.8735\n",
      "Epoch 17/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.2367 - f1_m: 0.9206 - precision_m: 0.9355 - recall_m: 0.906 - ETA: 0s - loss: 0.3098 - f1_m: 0.8886 - precision_m: 0.8955 - recall_m: 0.881 - ETA: 0s - loss: 0.3076 - f1_m: 0.8807 - precision_m: 0.8879 - recall_m: 0.873 - ETA: 0s - loss: 0.3066 - f1_m: 0.8814 - precision_m: 0.8884 - recall_m: 0.874 - ETA: 0s - loss: 0.3067 - f1_m: 0.8801 - precision_m: 0.8873 - recall_m: 0.873 - ETA: 0s - loss: 0.3055 - f1_m: 0.8803 - precision_m: 0.8877 - recall_m: 0.873 - ETA: 0s - loss: 0.3024 - f1_m: 0.8818 - precision_m: 0.8892 - recall_m: 0.874 - ETA: 0s - loss: 0.3023 - f1_m: 0.8815 - precision_m: 0.8889 - recall_m: 0.874 - 0s 12us/step - loss: 0.3037 - f1_m: 0.8809 - precision_m: 0.8885 - recall_m: 0.8738\n",
      "Epoch 18/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.1828 - f1_m: 0.9524 - precision_m: 0.9677 - recall_m: 0.937 - ETA: 0s - loss: 0.2904 - f1_m: 0.8879 - precision_m: 0.8935 - recall_m: 0.882 - ETA: 0s - loss: 0.2987 - f1_m: 0.8847 - precision_m: 0.8915 - recall_m: 0.878 - ETA: 0s - loss: 0.2994 - f1_m: 0.8856 - precision_m: 0.8926 - recall_m: 0.879 - ETA: 0s - loss: 0.2989 - f1_m: 0.8865 - precision_m: 0.8934 - recall_m: 0.879 - ETA: 0s - loss: 0.2976 - f1_m: 0.8863 - precision_m: 0.8932 - recall_m: 0.879 - ETA: 0s - loss: 0.2978 - f1_m: 0.8861 - precision_m: 0.8932 - recall_m: 0.879 - 0s 10us/step - loss: 0.2964 - f1_m: 0.8860 - precision_m: 0.8931 - recall_m: 0.8793\n",
      "Epoch 19/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.1652 - f1_m: 0.9206 - precision_m: 0.9355 - recall_m: 0.906 - ETA: 0s - loss: 0.2945 - f1_m: 0.8920 - precision_m: 0.8993 - recall_m: 0.885 - ETA: 0s - loss: 0.2975 - f1_m: 0.8886 - precision_m: 0.8957 - recall_m: 0.881 - ETA: 0s - loss: 0.2922 - f1_m: 0.8903 - precision_m: 0.8971 - recall_m: 0.883 - ETA: 0s - loss: 0.2921 - f1_m: 0.8896 - precision_m: 0.8962 - recall_m: 0.883 - ETA: 0s - loss: 0.2920 - f1_m: 0.8889 - precision_m: 0.8957 - recall_m: 0.882 - ETA: 0s - loss: 0.2917 - f1_m: 0.8888 - precision_m: 0.8956 - recall_m: 0.882 - 0s 10us/step - loss: 0.2922 - f1_m: 0.8888 - precision_m: 0.8957 - recall_m: 0.8822\n",
      "Epoch 20/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.2578 - f1_m: 0.8889 - precision_m: 0.9032 - recall_m: 0.875 - ETA: 0s - loss: 0.2854 - f1_m: 0.8887 - precision_m: 0.8947 - recall_m: 0.883 - ETA: 0s - loss: 0.2812 - f1_m: 0.8904 - precision_m: 0.8962 - recall_m: 0.884 - ETA: 0s - loss: 0.2834 - f1_m: 0.8901 - precision_m: 0.8960 - recall_m: 0.884 - ETA: 0s - loss: 0.2842 - f1_m: 0.8895 - precision_m: 0.8954 - recall_m: 0.883 - ETA: 0s - loss: 0.2830 - f1_m: 0.8901 - precision_m: 0.8960 - recall_m: 0.884 - ETA: 0s - loss: 0.2847 - f1_m: 0.8896 - precision_m: 0.8957 - recall_m: 0.883 - 0s 11us/step - loss: 0.2861 - f1_m: 0.8890 - precision_m: 0.8951 - recall_m: 0.8831\n",
      "Epoch 21/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.3980 - f1_m: 0.8750 - precision_m: 0.8750 - recall_m: 0.875 - ETA: 0s - loss: 0.2742 - f1_m: 0.8977 - precision_m: 0.9028 - recall_m: 0.892 - ETA: 0s - loss: 0.2804 - f1_m: 0.8932 - precision_m: 0.8984 - recall_m: 0.888 - ETA: 0s - loss: 0.2841 - f1_m: 0.8906 - precision_m: 0.8962 - recall_m: 0.885 - ETA: 0s - loss: 0.2825 - f1_m: 0.8911 - precision_m: 0.8970 - recall_m: 0.885 - ETA: 0s - loss: 0.2827 - f1_m: 0.8917 - precision_m: 0.8975 - recall_m: 0.886 - ETA: 0s - loss: 0.2856 - f1_m: 0.8909 - precision_m: 0.8968 - recall_m: 0.885 - 0s 11us/step - loss: 0.2844 - f1_m: 0.8913 - precision_m: 0.8973 - recall_m: 0.8857\n",
      "Epoch 22/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.3313 - f1_m: 0.8750 - precision_m: 0.8750 - recall_m: 0.875 - ETA: 0s - loss: 0.2686 - f1_m: 0.8949 - precision_m: 0.9002 - recall_m: 0.889 - ETA: 0s - loss: 0.2759 - f1_m: 0.8883 - precision_m: 0.8947 - recall_m: 0.882 - ETA: 0s - loss: 0.2776 - f1_m: 0.8901 - precision_m: 0.8963 - recall_m: 0.884 - ETA: 0s - loss: 0.2818 - f1_m: 0.8900 - precision_m: 0.8963 - recall_m: 0.884 - ETA: 0s - loss: 0.2803 - f1_m: 0.8914 - precision_m: 0.8975 - recall_m: 0.885 - ETA: 0s - loss: 0.2796 - f1_m: 0.8924 - precision_m: 0.8983 - recall_m: 0.886 - 0s 10us/step - loss: 0.2784 - f1_m: 0.8925 - precision_m: 0.8985 - recall_m: 0.8868\n",
      "Epoch 23/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.2562 - f1_m: 0.9524 - precision_m: 0.9677 - recall_m: 0.937 - ETA: 0s - loss: 0.2676 - f1_m: 0.8981 - precision_m: 0.9030 - recall_m: 0.893 - ETA: 0s - loss: 0.2753 - f1_m: 0.8953 - precision_m: 0.9005 - recall_m: 0.890 - ETA: 0s - loss: 0.2753 - f1_m: 0.8963 - precision_m: 0.9020 - recall_m: 0.890 - ETA: 0s - loss: 0.2770 - f1_m: 0.8960 - precision_m: 0.9018 - recall_m: 0.890 - ETA: 0s - loss: 0.2764 - f1_m: 0.8961 - precision_m: 0.9022 - recall_m: 0.890 - ETA: 0s - loss: 0.2744 - f1_m: 0.8965 - precision_m: 0.9025 - recall_m: 0.890 - 0s 10us/step - loss: 0.2745 - f1_m: 0.8964 - precision_m: 0.9024 - recall_m: 0.8906\n",
      "Epoch 24/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.1332 - f1_m: 0.9687 - precision_m: 0.9688 - recall_m: 0.968 - ETA: 0s - loss: 0.2576 - f1_m: 0.8979 - precision_m: 0.9057 - recall_m: 0.890 - ETA: 0s - loss: 0.2649 - f1_m: 0.8978 - precision_m: 0.9047 - recall_m: 0.891 - ETA: 0s - loss: 0.2679 - f1_m: 0.8958 - precision_m: 0.9021 - recall_m: 0.889 - ETA: 0s - loss: 0.2684 - f1_m: 0.8970 - precision_m: 0.9031 - recall_m: 0.891 - ETA: 0s - loss: 0.2704 - f1_m: 0.8961 - precision_m: 0.9019 - recall_m: 0.890 - ETA: 0s - loss: 0.2726 - f1_m: 0.8947 - precision_m: 0.9002 - recall_m: 0.889 - ETA: 0s - loss: 0.2724 - f1_m: 0.8957 - precision_m: 0.9011 - recall_m: 0.890 - 0s 11us/step - loss: 0.2727 - f1_m: 0.8956 - precision_m: 0.9010 - recall_m: 0.8905\n",
      "Epoch 25/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.2102 - f1_m: 0.9375 - precision_m: 0.9375 - recall_m: 0.937 - ETA: 0s - loss: 0.2702 - f1_m: 0.8980 - precision_m: 0.9038 - recall_m: 0.892 - ETA: 0s - loss: 0.2634 - f1_m: 0.8995 - precision_m: 0.9051 - recall_m: 0.894 - ETA: 0s - loss: 0.2611 - f1_m: 0.9002 - precision_m: 0.9058 - recall_m: 0.894 - ETA: 0s - loss: 0.2670 - f1_m: 0.8986 - precision_m: 0.9042 - recall_m: 0.893 - ETA: 0s - loss: 0.2683 - f1_m: 0.8984 - precision_m: 0.9040 - recall_m: 0.893 - ETA: 0s - loss: 0.2682 - f1_m: 0.8985 - precision_m: 0.9039 - recall_m: 0.893 - ETA: 0s - loss: 0.2678 - f1_m: 0.8982 - precision_m: 0.9036 - recall_m: 0.893 - 0s 12us/step - loss: 0.2685 - f1_m: 0.8982 - precision_m: 0.9035 - recall_m: 0.8931\n",
      "Epoch 26/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.3789 - f1_m: 0.8571 - precision_m: 0.8710 - recall_m: 0.843 - ETA: 0s - loss: 0.2547 - f1_m: 0.9027 - precision_m: 0.9070 - recall_m: 0.898 - ETA: 0s - loss: 0.2568 - f1_m: 0.9031 - precision_m: 0.9079 - recall_m: 0.898 - ETA: 0s - loss: 0.2653 - f1_m: 0.8989 - precision_m: 0.9041 - recall_m: 0.894 - ETA: 0s - loss: 0.2664 - f1_m: 0.8986 - precision_m: 0.9039 - recall_m: 0.893 - ETA: 0s - loss: 0.2690 - f1_m: 0.8976 - precision_m: 0.9029 - recall_m: 0.892 - ETA: 0s - loss: 0.2664 - f1_m: 0.8982 - precision_m: 0.9034 - recall_m: 0.893 - 0s 10us/step - loss: 0.2672 - f1_m: 0.8978 - precision_m: 0.9029 - recall_m: 0.8929\n",
      "Epoch 27/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.1984 - f1_m: 0.9375 - precision_m: 0.9375 - recall_m: 0.937 - ETA: 0s - loss: 0.2501 - f1_m: 0.9092 - precision_m: 0.9139 - recall_m: 0.904 - ETA: 0s - loss: 0.2572 - f1_m: 0.9060 - precision_m: 0.9109 - recall_m: 0.901 - ETA: 0s - loss: 0.2614 - f1_m: 0.9033 - precision_m: 0.9084 - recall_m: 0.898 - ETA: 0s - loss: 0.2633 - f1_m: 0.9012 - precision_m: 0.9062 - recall_m: 0.896 - ETA: 0s - loss: 0.2627 - f1_m: 0.9013 - precision_m: 0.9062 - recall_m: 0.896 - ETA: 0s - loss: 0.2625 - f1_m: 0.9012 - precision_m: 0.9061 - recall_m: 0.896 - 0s 10us/step - loss: 0.2628 - f1_m: 0.9004 - precision_m: 0.9052 - recall_m: 0.8958\n",
      "Epoch 28/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.3543 - f1_m: 0.8525 - precision_m: 0.8966 - recall_m: 0.812 - ETA: 0s - loss: 0.2546 - f1_m: 0.9067 - precision_m: 0.9119 - recall_m: 0.901 - ETA: 0s - loss: 0.2494 - f1_m: 0.9045 - precision_m: 0.9093 - recall_m: 0.899 - ETA: 0s - loss: 0.2540 - f1_m: 0.9017 - precision_m: 0.9065 - recall_m: 0.897 - ETA: 0s - loss: 0.2571 - f1_m: 0.9003 - precision_m: 0.9051 - recall_m: 0.895 - ETA: 0s - loss: 0.2577 - f1_m: 0.8998 - precision_m: 0.9048 - recall_m: 0.895 - ETA: 0s - loss: 0.2595 - f1_m: 0.8990 - precision_m: 0.9038 - recall_m: 0.894 - 0s 10us/step - loss: 0.2601 - f1_m: 0.8986 - precision_m: 0.9035 - recall_m: 0.8939\n",
      "Epoch 29/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.4024 - f1_m: 0.8125 - precision_m: 0.8125 - recall_m: 0.812 - ETA: 0s - loss: 0.2616 - f1_m: 0.8998 - precision_m: 0.9050 - recall_m: 0.894 - ETA: 0s - loss: 0.2577 - f1_m: 0.9021 - precision_m: 0.9072 - recall_m: 0.897 - ETA: 0s - loss: 0.2620 - f1_m: 0.9009 - precision_m: 0.9060 - recall_m: 0.895 - ETA: 0s - loss: 0.2601 - f1_m: 0.9026 - precision_m: 0.9076 - recall_m: 0.897 - ETA: 0s - loss: 0.2588 - f1_m: 0.9030 - precision_m: 0.9083 - recall_m: 0.897 - ETA: 0s - loss: 0.2590 - f1_m: 0.9022 - precision_m: 0.9075 - recall_m: 0.897 - 0s 10us/step - loss: 0.2587 - f1_m: 0.9026 - precision_m: 0.9079 - recall_m: 0.8975\n",
      "Epoch 30/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.2574 - f1_m: 0.9375 - precision_m: 0.9375 - recall_m: 0.937 - ETA: 0s - loss: 0.2425 - f1_m: 0.9089 - precision_m: 0.9123 - recall_m: 0.905 - ETA: 0s - loss: 0.2503 - f1_m: 0.9054 - precision_m: 0.9099 - recall_m: 0.901 - ETA: 0s - loss: 0.2548 - f1_m: 0.9021 - precision_m: 0.9071 - recall_m: 0.897 - ETA: 0s - loss: 0.2529 - f1_m: 0.9025 - precision_m: 0.9074 - recall_m: 0.897 - ETA: 0s - loss: 0.2532 - f1_m: 0.9021 - precision_m: 0.9070 - recall_m: 0.897 - ETA: 0s - loss: 0.2534 - f1_m: 0.9029 - precision_m: 0.9079 - recall_m: 0.898 - 0s 10us/step - loss: 0.2547 - f1_m: 0.9025 - precision_m: 0.9074 - recall_m: 0.8979\n",
      "Epoch 31/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.2591 - f1_m: 0.9375 - precision_m: 0.9375 - recall_m: 0.937 - ETA: 0s - loss: 0.2494 - f1_m: 0.9083 - precision_m: 0.9118 - recall_m: 0.904 - ETA: 0s - loss: 0.2486 - f1_m: 0.9083 - precision_m: 0.9118 - recall_m: 0.905 - ETA: 0s - loss: 0.2475 - f1_m: 0.9081 - precision_m: 0.9117 - recall_m: 0.904 - ETA: 0s - loss: 0.2500 - f1_m: 0.9065 - precision_m: 0.9103 - recall_m: 0.902 - ETA: 0s - loss: 0.2495 - f1_m: 0.9073 - precision_m: 0.9110 - recall_m: 0.903 - ETA: 0s - loss: 0.2509 - f1_m: 0.9066 - precision_m: 0.9105 - recall_m: 0.902 - 0s 10us/step - loss: 0.2512 - f1_m: 0.9059 - precision_m: 0.9099 - recall_m: 0.9021\n",
      "Epoch 32/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.0950 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.000 - ETA: 0s - loss: 0.2558 - f1_m: 0.9030 - precision_m: 0.9070 - recall_m: 0.899 - ETA: 0s - loss: 0.2519 - f1_m: 0.9036 - precision_m: 0.9076 - recall_m: 0.899 - ETA: 0s - loss: 0.2494 - f1_m: 0.9063 - precision_m: 0.9103 - recall_m: 0.902 - ETA: 0s - loss: 0.2503 - f1_m: 0.9058 - precision_m: 0.9099 - recall_m: 0.901 - ETA: 0s - loss: 0.2500 - f1_m: 0.9060 - precision_m: 0.9104 - recall_m: 0.901 - ETA: 0s - loss: 0.2497 - f1_m: 0.9055 - precision_m: 0.9098 - recall_m: 0.901 - 0s 10us/step - loss: 0.2500 - f1_m: 0.9053 - precision_m: 0.9095 - recall_m: 0.9012\n",
      "Epoch 33/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.1798 - f1_m: 0.9375 - precision_m: 0.9375 - recall_m: 0.937 - ETA: 0s - loss: 0.2353 - f1_m: 0.9132 - precision_m: 0.9169 - recall_m: 0.909 - ETA: 0s - loss: 0.2423 - f1_m: 0.9115 - precision_m: 0.9156 - recall_m: 0.907 - ETA: 0s - loss: 0.2458 - f1_m: 0.9080 - precision_m: 0.9120 - recall_m: 0.904 - ETA: 0s - loss: 0.2465 - f1_m: 0.9073 - precision_m: 0.9113 - recall_m: 0.903 - ETA: 0s - loss: 0.2476 - f1_m: 0.9066 - precision_m: 0.9107 - recall_m: 0.902 - ETA: 0s - loss: 0.2464 - f1_m: 0.9065 - precision_m: 0.9106 - recall_m: 0.902 - 0s 10us/step - loss: 0.2469 - f1_m: 0.9062 - precision_m: 0.9103 - recall_m: 0.9023\n",
      "Epoch 34/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.2636 - f1_m: 0.8750 - precision_m: 0.8750 - recall_m: 0.875 - ETA: 0s - loss: 0.2429 - f1_m: 0.9086 - precision_m: 0.9114 - recall_m: 0.905 - ETA: 0s - loss: 0.2426 - f1_m: 0.9084 - precision_m: 0.9117 - recall_m: 0.905 - ETA: 0s - loss: 0.2455 - f1_m: 0.9060 - precision_m: 0.9095 - recall_m: 0.902 - ETA: 0s - loss: 0.2465 - f1_m: 0.9062 - precision_m: 0.9100 - recall_m: 0.902 - ETA: 0s - loss: 0.2463 - f1_m: 0.9062 - precision_m: 0.9101 - recall_m: 0.902 - ETA: 0s - loss: 0.2446 - f1_m: 0.9069 - precision_m: 0.9108 - recall_m: 0.903 - 0s 10us/step - loss: 0.2450 - f1_m: 0.9064 - precision_m: 0.9103 - recall_m: 0.9026\n",
      "Epoch 35/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.1950 - f1_m: 0.9062 - precision_m: 0.9062 - recall_m: 0.906 - ETA: 0s - loss: 0.2382 - f1_m: 0.9086 - precision_m: 0.9124 - recall_m: 0.905 - ETA: 0s - loss: 0.2408 - f1_m: 0.9092 - precision_m: 0.9129 - recall_m: 0.905 - ETA: 0s - loss: 0.2413 - f1_m: 0.9080 - precision_m: 0.9120 - recall_m: 0.904 - ETA: 0s - loss: 0.2436 - f1_m: 0.9076 - precision_m: 0.9116 - recall_m: 0.903 - ETA: 0s - loss: 0.2427 - f1_m: 0.9073 - precision_m: 0.9111 - recall_m: 0.903 - ETA: 0s - loss: 0.2440 - f1_m: 0.9072 - precision_m: 0.9110 - recall_m: 0.903 - 0s 10us/step - loss: 0.2429 - f1_m: 0.9075 - precision_m: 0.9113 - recall_m: 0.9038\n",
      "Epoch 36/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.3147 - f1_m: 0.9062 - precision_m: 0.9062 - recall_m: 0.906 - ETA: 0s - loss: 0.2556 - f1_m: 0.9000 - precision_m: 0.9048 - recall_m: 0.895 - ETA: 0s - loss: 0.2471 - f1_m: 0.9075 - precision_m: 0.9115 - recall_m: 0.903 - ETA: 0s - loss: 0.2406 - f1_m: 0.9087 - precision_m: 0.9127 - recall_m: 0.904 - ETA: 0s - loss: 0.2410 - f1_m: 0.9077 - precision_m: 0.9118 - recall_m: 0.903 - ETA: 0s - loss: 0.2412 - f1_m: 0.9074 - precision_m: 0.9114 - recall_m: 0.903 - ETA: 0s - loss: 0.2397 - f1_m: 0.9084 - precision_m: 0.9125 - recall_m: 0.904 - 0s 10us/step - loss: 0.2394 - f1_m: 0.9088 - precision_m: 0.9128 - recall_m: 0.9049\n",
      "Epoch 37/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.1970 - f1_m: 0.9375 - precision_m: 0.9375 - recall_m: 0.937 - ETA: 0s - loss: 0.2422 - f1_m: 0.9054 - precision_m: 0.9091 - recall_m: 0.901 - ETA: 0s - loss: 0.2421 - f1_m: 0.9056 - precision_m: 0.9088 - recall_m: 0.902 - ETA: 0s - loss: 0.2391 - f1_m: 0.9073 - precision_m: 0.9107 - recall_m: 0.904 - ETA: 0s - loss: 0.2404 - f1_m: 0.9069 - precision_m: 0.9104 - recall_m: 0.903 - ETA: 0s - loss: 0.2404 - f1_m: 0.9075 - precision_m: 0.9110 - recall_m: 0.904 - ETA: 0s - loss: 0.2387 - f1_m: 0.9080 - precision_m: 0.9115 - recall_m: 0.904 - 0s 10us/step - loss: 0.2373 - f1_m: 0.9089 - precision_m: 0.9125 - recall_m: 0.9055\n",
      "Epoch 38/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.2477 - f1_m: 0.9375 - precision_m: 0.9375 - recall_m: 0.937 - ETA: 0s - loss: 0.2386 - f1_m: 0.9107 - precision_m: 0.9147 - recall_m: 0.906 - ETA: 0s - loss: 0.2345 - f1_m: 0.9135 - precision_m: 0.9173 - recall_m: 0.909 - ETA: 0s - loss: 0.2335 - f1_m: 0.9126 - precision_m: 0.9164 - recall_m: 0.908 - ETA: 0s - loss: 0.2336 - f1_m: 0.9112 - precision_m: 0.9152 - recall_m: 0.907 - ETA: 0s - loss: 0.2340 - f1_m: 0.9101 - precision_m: 0.9142 - recall_m: 0.906 - ETA: 0s - loss: 0.2348 - f1_m: 0.9101 - precision_m: 0.9142 - recall_m: 0.906 - 0s 10us/step - loss: 0.2366 - f1_m: 0.9095 - precision_m: 0.9135 - recall_m: 0.9057\n",
      "Epoch 39/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.2857 - f1_m: 0.8750 - precision_m: 0.8750 - recall_m: 0.875 - ETA: 0s - loss: 0.2371 - f1_m: 0.9073 - precision_m: 0.9110 - recall_m: 0.903 - ETA: 0s - loss: 0.2312 - f1_m: 0.9093 - precision_m: 0.9129 - recall_m: 0.905 - ETA: 0s - loss: 0.2324 - f1_m: 0.9100 - precision_m: 0.9133 - recall_m: 0.906 - ETA: 0s - loss: 0.2339 - f1_m: 0.9092 - precision_m: 0.9128 - recall_m: 0.905 - ETA: 0s - loss: 0.2313 - f1_m: 0.9105 - precision_m: 0.9139 - recall_m: 0.907 - ETA: 0s - loss: 0.2329 - f1_m: 0.9103 - precision_m: 0.9136 - recall_m: 0.907 - 0s 11us/step - loss: 0.2334 - f1_m: 0.9098 - precision_m: 0.9132 - recall_m: 0.9066\n",
      "Epoch 40/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.0999 - f1_m: 1.0000 - precision_m: 1.0000 - recall_m: 1.000 - ETA: 0s - loss: 0.2263 - f1_m: 0.9194 - precision_m: 0.9225 - recall_m: 0.916 - ETA: 0s - loss: 0.2329 - f1_m: 0.9143 - precision_m: 0.9180 - recall_m: 0.910 - ETA: 0s - loss: 0.2298 - f1_m: 0.9139 - precision_m: 0.9176 - recall_m: 0.910 - ETA: 0s - loss: 0.2299 - f1_m: 0.9130 - precision_m: 0.9167 - recall_m: 0.909 - ETA: 0s - loss: 0.2293 - f1_m: 0.9133 - precision_m: 0.9168 - recall_m: 0.910 - ETA: 0s - loss: 0.2299 - f1_m: 0.9133 - precision_m: 0.9168 - recall_m: 0.910 - 0s 11us/step - loss: 0.2301 - f1_m: 0.9132 - precision_m: 0.9167 - recall_m: 0.9099\n",
      "Epoch 41/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.1529 - f1_m: 0.9687 - precision_m: 0.9688 - recall_m: 0.968 - ETA: 0s - loss: 0.2121 - f1_m: 0.9165 - precision_m: 0.9202 - recall_m: 0.912 - ETA: 0s - loss: 0.2174 - f1_m: 0.9168 - precision_m: 0.9206 - recall_m: 0.913 - ETA: 0s - loss: 0.2198 - f1_m: 0.9173 - precision_m: 0.9208 - recall_m: 0.914 - ETA: 0s - loss: 0.2215 - f1_m: 0.9166 - precision_m: 0.9200 - recall_m: 0.913 - ETA: 0s - loss: 0.2242 - f1_m: 0.9156 - precision_m: 0.9190 - recall_m: 0.912 - ETA: 0s - loss: 0.2259 - f1_m: 0.9149 - precision_m: 0.9183 - recall_m: 0.911 - ETA: 0s - loss: 0.2282 - f1_m: 0.9138 - precision_m: 0.9173 - recall_m: 0.910 - 0s 11us/step - loss: 0.2285 - f1_m: 0.9135 - precision_m: 0.9169 - recall_m: 0.9102\n",
      "Epoch 42/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.0736 - f1_m: 0.9841 - precision_m: 1.0000 - recall_m: 0.968 - ETA: 0s - loss: 0.2326 - f1_m: 0.9121 - precision_m: 0.9161 - recall_m: 0.908 - ETA: 0s - loss: 0.2247 - f1_m: 0.9148 - precision_m: 0.9188 - recall_m: 0.911 - ETA: 0s - loss: 0.2282 - f1_m: 0.9140 - precision_m: 0.9175 - recall_m: 0.910 - ETA: 0s - loss: 0.2261 - f1_m: 0.9140 - precision_m: 0.9175 - recall_m: 0.910 - ETA: 0s - loss: 0.2275 - f1_m: 0.9137 - precision_m: 0.9172 - recall_m: 0.910 - ETA: 0s - loss: 0.2281 - f1_m: 0.9137 - precision_m: 0.9171 - recall_m: 0.910 - 0s 10us/step - loss: 0.2273 - f1_m: 0.9141 - precision_m: 0.9175 - recall_m: 0.9108\n",
      "Epoch 43/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.4321 - f1_m: 0.8437 - precision_m: 0.8438 - recall_m: 0.843 - ETA: 0s - loss: 0.2226 - f1_m: 0.9161 - precision_m: 0.9198 - recall_m: 0.912 - ETA: 0s - loss: 0.2235 - f1_m: 0.9141 - precision_m: 0.9173 - recall_m: 0.910 - ETA: 0s - loss: 0.2252 - f1_m: 0.9144 - precision_m: 0.9179 - recall_m: 0.911 - ETA: 0s - loss: 0.2279 - f1_m: 0.9137 - precision_m: 0.9171 - recall_m: 0.910 - ETA: 0s - loss: 0.2277 - f1_m: 0.9132 - precision_m: 0.9167 - recall_m: 0.909 - ETA: 0s - loss: 0.2262 - f1_m: 0.9138 - precision_m: 0.9173 - recall_m: 0.910 - 0s 10us/step - loss: 0.2268 - f1_m: 0.9135 - precision_m: 0.9169 - recall_m: 0.9102\n",
      "Epoch 44/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.2270 - f1_m: 0.9375 - precision_m: 0.9375 - recall_m: 0.937 - ETA: 0s - loss: 0.2118 - f1_m: 0.9217 - precision_m: 0.9247 - recall_m: 0.918 - ETA: 0s - loss: 0.2224 - f1_m: 0.9183 - precision_m: 0.9214 - recall_m: 0.915 - ETA: 0s - loss: 0.2222 - f1_m: 0.9184 - precision_m: 0.9215 - recall_m: 0.915 - ETA: 0s - loss: 0.2200 - f1_m: 0.9182 - precision_m: 0.9213 - recall_m: 0.915 - ETA: 0s - loss: 0.2216 - f1_m: 0.9169 - precision_m: 0.9201 - recall_m: 0.913 - ETA: 0s - loss: 0.2237 - f1_m: 0.9154 - precision_m: 0.9188 - recall_m: 0.912 - 0s 10us/step - loss: 0.2249 - f1_m: 0.9151 - precision_m: 0.9185 - recall_m: 0.9118\n",
      "Epoch 45/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.1999 - f1_m: 0.9062 - precision_m: 0.9062 - recall_m: 0.906 - ETA: 0s - loss: 0.2156 - f1_m: 0.9208 - precision_m: 0.9246 - recall_m: 0.917 - ETA: 0s - loss: 0.2172 - f1_m: 0.9185 - precision_m: 0.9219 - recall_m: 0.915 - ETA: 0s - loss: 0.2218 - f1_m: 0.9167 - precision_m: 0.9201 - recall_m: 0.913 - ETA: 0s - loss: 0.2234 - f1_m: 0.9164 - precision_m: 0.9196 - recall_m: 0.913 - ETA: 0s - loss: 0.2238 - f1_m: 0.9162 - precision_m: 0.9195 - recall_m: 0.913 - ETA: 0s - loss: 0.2233 - f1_m: 0.9161 - precision_m: 0.9193 - recall_m: 0.913 - 0s 11us/step - loss: 0.2223 - f1_m: 0.9165 - precision_m: 0.9197 - recall_m: 0.9135\n",
      "Epoch 46/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.3051 - f1_m: 0.8750 - precision_m: 0.8750 - recall_m: 0.875 - ETA: 0s - loss: 0.2163 - f1_m: 0.9202 - precision_m: 0.9232 - recall_m: 0.917 - ETA: 0s - loss: 0.2086 - f1_m: 0.9239 - precision_m: 0.9267 - recall_m: 0.921 - ETA: 0s - loss: 0.2147 - f1_m: 0.9206 - precision_m: 0.9235 - recall_m: 0.917 - ETA: 0s - loss: 0.2142 - f1_m: 0.9210 - precision_m: 0.9242 - recall_m: 0.918 - ETA: 0s - loss: 0.2157 - f1_m: 0.9205 - precision_m: 0.9238 - recall_m: 0.917 - ETA: 0s - loss: 0.2171 - f1_m: 0.9200 - precision_m: 0.9234 - recall_m: 0.916 - 0s 10us/step - loss: 0.2205 - f1_m: 0.9183 - precision_m: 0.9217 - recall_m: 0.9151\n",
      "Epoch 47/50\n",
      "33191/33191 [==============================] - ETA: 1s - loss: 0.2937 - f1_m: 0.9206 - precision_m: 0.9355 - recall_m: 0.906 - ETA: 0s - loss: 0.2189 - f1_m: 0.9145 - precision_m: 0.9176 - recall_m: 0.911 - ETA: 0s - loss: 0.2192 - f1_m: 0.9167 - precision_m: 0.9199 - recall_m: 0.913 - ETA: 0s - loss: 0.2198 - f1_m: 0.9169 - precision_m: 0.9201 - recall_m: 0.913 - ETA: 0s - loss: 0.2199 - f1_m: 0.9165 - precision_m: 0.9197 - recall_m: 0.913 - ETA: 0s - loss: 0.2197 - f1_m: 0.9170 - precision_m: 0.9203 - recall_m: 0.913 - ETA: 0s - loss: 0.2195 - f1_m: 0.9171 - precision_m: 0.9205 - recall_m: 0.913 - 0s 10us/step - loss: 0.2189 - f1_m: 0.9177 - precision_m: 0.9211 - recall_m: 0.9144\n",
      "Epoch 48/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.3006 - f1_m: 0.8750 - precision_m: 0.8750 - recall_m: 0.875 - ETA: 0s - loss: 0.2162 - f1_m: 0.9211 - precision_m: 0.9240 - recall_m: 0.918 - ETA: 0s - loss: 0.2134 - f1_m: 0.9205 - precision_m: 0.9237 - recall_m: 0.917 - ETA: 0s - loss: 0.2173 - f1_m: 0.9192 - precision_m: 0.9225 - recall_m: 0.916 - ETA: 0s - loss: 0.2161 - f1_m: 0.9190 - precision_m: 0.9221 - recall_m: 0.916 - ETA: 0s - loss: 0.2156 - f1_m: 0.9189 - precision_m: 0.9220 - recall_m: 0.916 - ETA: 0s - loss: 0.2147 - f1_m: 0.9196 - precision_m: 0.9227 - recall_m: 0.916 - 0s 10us/step - loss: 0.2158 - f1_m: 0.9196 - precision_m: 0.9227 - recall_m: 0.9166\n",
      "Epoch 49/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.1561 - f1_m: 0.9687 - precision_m: 0.9688 - recall_m: 0.968 - ETA: 0s - loss: 0.2009 - f1_m: 0.9238 - precision_m: 0.9274 - recall_m: 0.920 - ETA: 0s - loss: 0.2096 - f1_m: 0.9227 - precision_m: 0.9257 - recall_m: 0.919 - ETA: 0s - loss: 0.2122 - f1_m: 0.9210 - precision_m: 0.9241 - recall_m: 0.918 - ETA: 0s - loss: 0.2119 - f1_m: 0.9200 - precision_m: 0.9230 - recall_m: 0.917 - ETA: 0s - loss: 0.2122 - f1_m: 0.9195 - precision_m: 0.9225 - recall_m: 0.916 - ETA: 0s - loss: 0.2141 - f1_m: 0.9191 - precision_m: 0.9222 - recall_m: 0.916 - 0s 10us/step - loss: 0.2162 - f1_m: 0.9185 - precision_m: 0.9217 - recall_m: 0.9154\n",
      "Epoch 50/50\n",
      "33191/33191 [==============================] - ETA: 2s - loss: 0.3039 - f1_m: 0.9062 - precision_m: 0.9062 - recall_m: 0.906 - ETA: 0s - loss: 0.2103 - f1_m: 0.9201 - precision_m: 0.9224 - recall_m: 0.917 - ETA: 0s - loss: 0.2125 - f1_m: 0.9187 - precision_m: 0.9218 - recall_m: 0.915 - ETA: 0s - loss: 0.2101 - f1_m: 0.9214 - precision_m: 0.9244 - recall_m: 0.918 - ETA: 0s - loss: 0.2112 - f1_m: 0.9209 - precision_m: 0.9239 - recall_m: 0.918 - ETA: 0s - loss: 0.2162 - f1_m: 0.9185 - precision_m: 0.9216 - recall_m: 0.915 - ETA: 0s - loss: 0.2148 - f1_m: 0.9200 - precision_m: 0.9231 - recall_m: 0.917 - 0s 10us/step - loss: 0.2142 - f1_m: 0.9198 - precision_m: 0.9228 - recall_m: 0.9169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bde59eac88>"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nmodel.fit(X, dummy_y, epochs=50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y_test = Nmodel.predict(X_test)\n",
    "pred_y_testNN = np.argmax(pred_y_test,axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3380640013831903\n"
     ]
    }
   ],
   "source": [
    "a=precision_recall_fscore_support(y_test, list(pred_y_testNN))\n",
    "f1s=a[2]\n",
    "prec_rec+=[a[0]]\n",
    "recal_rec+=[a[1]]\n",
    "# create the weighted f1 score: larger emphasis on high-votes bin and medium\n",
    "# adjusted f1_forall= (f1_low+f1_mid*2+f1_high*3)/6\n",
    "adjf1=(f1s[0]+f1s[1]*2+f1s[2]*3)/6\n",
    "print(adjf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix: [[8759  522  202]\n",
      " [ 128  155   35]\n",
      " [  24   14   25]]\n",
      "other metrics:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      9483\n",
      "           1       0.22      0.49      0.31       318\n",
      "           2       0.10      0.40      0.15        63\n",
      "\n",
      "    accuracy                           0.91      9864\n",
      "   macro avg       0.43      0.60      0.47      9864\n",
      "weighted avg       0.95      0.91      0.93      9864\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix-- testing\n",
    "print(\"confusion matrix:\",confusion_matrix(y_test, pred_y_testNN))\n",
    "print(\"other metrics:\",classification_report(y_test, pred_y_testNN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
