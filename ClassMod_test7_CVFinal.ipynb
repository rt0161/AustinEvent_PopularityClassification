{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from fastparquet import ParquetFile,write\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from tqdm import tqdm\n",
    "\n",
    "from cm2df import cm2df,precision_recall_fscore_support_metrics2df\n",
    "from sklearn.metrics import confusion_matrix, classification_report,precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the trainign data (cleaned and encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf=ParquetFile('subset_feature_4ML_110619.parq')\n",
    "udf=pf.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32880 entries, 11049447 to 9968570\n",
      "Data columns (total 35 columns):\n",
      "category                 32880 non-null int64\n",
      "past                     32880 non-null int32\n",
      "votes                    32880 non-null int64\n",
      "is_eventbrite            32880 non-null int32\n",
      "is_free                  32880 non-null int32\n",
      "doors                    32880 non-null int32\n",
      "sold_out                 32880 non-null int32\n",
      "venue.id                 32880 non-null int64\n",
      "venue.popularity         32880 non-null float64\n",
      "venue.zip                32880 non-null int64\n",
      "ticket_allages           32880 non-null int32\n",
      "ticket_price_low         32880 non-null float64\n",
      "ticket_price_max         32880 non-null float64\n",
      "min_age                  32880 non-null int32\n",
      "artist.popularity.sum    32880 non-null float64\n",
      "artist.popularity.avg    32880 non-null float64\n",
      "artist.popularity.max    32880 non-null float64\n",
      "dow                      32880 non-null int64\n",
      "doy                      32880 non-null int64\n",
      "month                    32880 non-null int64\n",
      "day                      32880 non-null int64\n",
      "hour                     32880 non-null int64\n",
      "venue.tol_num_events     32880 non-null int64\n",
      "ev_id                    32880 non-null int64\n",
      "title                    32880 non-null object\n",
      "venue.title              32880 non-null object\n",
      "venue.address            32806 non-null object\n",
      "venue.city               32880 non-null object\n",
      "venue.state              32880 non-null object\n",
      "venue.latitude           32880 non-null float64\n",
      "venue.longitude          32880 non-null float64\n",
      "duration                 32880 non-null float64\n",
      "duration_day             32880 non-null float64\n",
      "multiday                 32880 non-null bool\n",
      "avg_votes_pday           32880 non-null float64\n",
      "dtypes: bool(1), float64(11), int32(7), int64(11), object(5)\n",
      "memory usage: 7.9+ MB\n"
     ]
    }
   ],
   "source": [
    "udf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf['multiday'] = udf['multiday'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>past</th>\n",
       "      <th>votes</th>\n",
       "      <th>is_eventbrite</th>\n",
       "      <th>is_free</th>\n",
       "      <th>doors</th>\n",
       "      <th>sold_out</th>\n",
       "      <th>venue.id</th>\n",
       "      <th>venue.popularity</th>\n",
       "      <th>venue.zip</th>\n",
       "      <th>...</th>\n",
       "      <th>venue.title</th>\n",
       "      <th>venue.address</th>\n",
       "      <th>venue.city</th>\n",
       "      <th>venue.state</th>\n",
       "      <th>venue.latitude</th>\n",
       "      <th>venue.longitude</th>\n",
       "      <th>duration</th>\n",
       "      <th>duration_day</th>\n",
       "      <th>multiday</th>\n",
       "      <th>avg_votes_pday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11049447</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>784</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Stubb's</td>\n",
       "      <td>801 Red River</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>30.268458</td>\n",
       "      <td>-97.736175</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>784.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11049456</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>223</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>Emo's</td>\n",
       "      <td>2015 E. Riverside Dr.</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>30.240266</td>\n",
       "      <td>-97.728516</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>223.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11049430</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>Historic Scoot Inn</td>\n",
       "      <td>1308 E. Fourth</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>30.262141</td>\n",
       "      <td>-97.729385</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>163.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11141496</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>126</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>Fallout Theater</td>\n",
       "      <td>616 Lavaca St</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>30.269536</td>\n",
       "      <td>-97.745230</td>\n",
       "      <td>6.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11109390</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>94</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>The Brixton</td>\n",
       "      <td>1412 E. 6th Street</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>30.263590</td>\n",
       "      <td>-97.727604</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>83.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          category  past  votes  is_eventbrite  is_free  doors  sold_out  \\\n",
       "id                                                                         \n",
       "11049447         0     0    784              0        0      1         0   \n",
       "11049456         0     0    223              0        0      1         0   \n",
       "11049430         0     0    163              0        0      1         0   \n",
       "11141496         1     0    126              1        0      1         0   \n",
       "11109390         1     0     83              0        1      0         0   \n",
       "\n",
       "          venue.id  venue.popularity  venue.zip  ...         venue.title  \\\n",
       "id                                               ...                       \n",
       "11049447        15              15.0          0  ...             Stubb's   \n",
       "11049456        70              15.0          8  ...               Emo's   \n",
       "11049430        29              15.0          2  ...  Historic Scoot Inn   \n",
       "11141496        28               1.0          0  ...     Fallout Theater   \n",
       "11109390        94               1.0          2  ...         The Brixton   \n",
       "\n",
       "                  venue.address  venue.city  venue.state  venue.latitude  \\\n",
       "id                                                                         \n",
       "11049447          801 Red River      Austin           TX       30.268458   \n",
       "11049456  2015 E. Riverside Dr.      Austin           TX       30.240266   \n",
       "11049430         1308 E. Fourth      Austin           TX       30.262141   \n",
       "11141496          616 Lavaca St      Austin           TX       30.269536   \n",
       "11109390     1412 E. 6th Street      Austin           TX       30.263590   \n",
       "\n",
       "          venue.longitude  duration  duration_day  multiday  avg_votes_pday  \n",
       "id                                                                           \n",
       "11049447       -97.736175       7.0           1.0         0           784.0  \n",
       "11049456       -97.728516       6.0           1.0         0           223.0  \n",
       "11049430       -97.729385       7.5           1.0         0           163.0  \n",
       "11141496       -97.745230       6.5           1.0         0           126.0  \n",
       "11109390       -97.727604       5.0           1.0         0            83.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "usecolsX=['category', 'past', 'is_eventbrite', 'is_free', 'doors',\n",
    "       'sold_out', 'venue.id', 'venue.popularity', 'venue.zip',\n",
    "       'ticket_allages', 'ticket_price_low', 'ticket_price_max', 'min_age',\n",
    "       'artist.popularity.sum', 'artist.popularity.avg',\n",
    "       'artist.popularity.max', 'dow', 'doy', 'month', 'day', 'hour',\n",
    "       'venue.tol_num_events', 'duration', 'duration_day', 'multiday']\n",
    "usecoly1=['votes']\n",
    "usecoly2=['avg_votes_pday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function to create udf_y based on 3 classes: low, mid, high\n",
    "def get_class(df,thre1,thre2):\n",
    "    n=len(df)\n",
    "    newdf=[]\n",
    "    cut1=min([thre1,thre2])\n",
    "    cut2=max([thre1,thre2])\n",
    "    for item in df:\n",
    "        if item<cut1: newdf+=[0]\n",
    "        elif (item<cut2) and (item>=cut1):newdf+=[1]\n",
    "        else: newdf+=[2]\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import algorithms for model comparisons\n",
    "# tree models\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "# scaling of the features\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model Estimator: Random Forest> + SMOTE Upsampling high votes to same as medium votes , best Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_X=udf[usecolsX+['votes']]\n",
    "udf_y=udf[usecoly1]\n",
    "y=get_class(udf_y.values,80,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "# do upsample with replacement\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# prepare the scaler beforehand\n",
    "scalar = MinMaxScaler()\n",
    "scalar.fit(udf_X.iloc[:,0:25])\n",
    "X = scalar.transform(udf_X.iloc[:,0:25])\n",
    "\n",
    "# setting up splits\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "skf.get_n_splits(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_pre_rec=[]\n",
    "cv_f1_rec=[]\n",
    "cv_recal_rec=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the testing data:\n",
      "number of low votes: 6323\n",
      "number of medium votes: 212\n",
      "number of high votes: 42\n",
      "in the training data:\n",
      "number of low votes: 25288\n",
      "number of medium votes: 847\n",
      "number of high votes: 847\n",
      "confusion matrix:\n",
      "[[6285   31    7]\n",
      " [ 132   71    9]\n",
      " [  23   10    9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98      6323\n",
      "           1       0.63      0.33      0.44       212\n",
      "           2       0.36      0.21      0.27        42\n",
      "\n",
      "    accuracy                           0.97      6577\n",
      "   macro avg       0.66      0.51      0.56      6577\n",
      "weighted avg       0.96      0.97      0.96      6577\n",
      "\n",
      "weighted f1 score: 0.44456525376191197\n",
      "in the testing data:\n",
      "number of low votes: 6322\n",
      "number of medium votes: 212\n",
      "number of high votes: 42\n",
      "in the training data:\n",
      "number of low votes: 25289\n",
      "number of medium votes: 847\n",
      "number of high votes: 847\n",
      "confusion matrix:\n",
      "[[6295   23    4]\n",
      " [ 125   81    6]\n",
      " [  27    5   10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      6322\n",
      "           1       0.74      0.38      0.50       212\n",
      "           2       0.50      0.24      0.32        42\n",
      "\n",
      "    accuracy                           0.97      6576\n",
      "   macro avg       0.74      0.54      0.60      6576\n",
      "weighted avg       0.97      0.97      0.97      6576\n",
      "\n",
      "weighted f1 score: 0.49384490070733394\n",
      "in the testing data:\n",
      "number of low votes: 6322\n",
      "number of medium votes: 212\n",
      "number of high votes: 42\n",
      "in the training data:\n",
      "number of low votes: 25289\n",
      "number of medium votes: 847\n",
      "number of high votes: 847\n",
      "confusion matrix:\n",
      "[[6291   12   19]\n",
      " [ 149   32   31]\n",
      " [  30    1   11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      6322\n",
      "           1       0.71      0.15      0.25       212\n",
      "           2       0.18      0.26      0.21        42\n",
      "\n",
      "    accuracy                           0.96      6576\n",
      "   macro avg       0.62      0.47      0.48      6576\n",
      "weighted avg       0.96      0.96      0.95      6576\n",
      "\n",
      "weighted f1 score: 0.3537357772363913\n",
      "in the testing data:\n",
      "number of low votes: 6322\n",
      "number of medium votes: 212\n",
      "number of high votes: 42\n",
      "in the training data:\n",
      "number of low votes: 25289\n",
      "number of medium votes: 847\n",
      "number of high votes: 847\n",
      "confusion matrix:\n",
      "[[6284   34    4]\n",
      " [ 154   55    3]\n",
      " [  25   12    5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      6322\n",
      "           1       0.54      0.26      0.35       212\n",
      "           2       0.42      0.12      0.19        42\n",
      "\n",
      "    accuracy                           0.96      6576\n",
      "   macro avg       0.64      0.46      0.51      6576\n",
      "weighted avg       0.95      0.96      0.96      6576\n",
      "\n",
      "weighted f1 score: 0.37357632327738816\n",
      "in the testing data:\n",
      "number of low votes: 6322\n",
      "number of medium votes: 211\n",
      "number of high votes: 42\n",
      "in the training data:\n",
      "number of low votes: 25289\n",
      "number of medium votes: 848\n",
      "number of high votes: 848\n",
      "confusion matrix:\n",
      "[[5574  731   17]\n",
      " [ 115   82   14]\n",
      " [  22    7   13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93      6322\n",
      "           1       0.10      0.39      0.16       211\n",
      "           2       0.30      0.31      0.30        42\n",
      "\n",
      "    accuracy                           0.86      6575\n",
      "   macro avg       0.46      0.53      0.46      6575\n",
      "weighted avg       0.94      0.86      0.90      6575\n",
      "\n",
      "weighted f1 score: 0.35859445514001836\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in skf.split(X, y):\n",
    "    # spliting the data\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train=[y[i] for i in train_index]\n",
    "    y_test =[y[i] for i in test_index]\n",
    "    print(\"in the testing data:\")\n",
    "    print(\"number of low votes:\",list(y_test).count(0))\n",
    "    print(\"number of medium votes:\",list(y_test).count(1))\n",
    "    print(\"number of high votes:\",list(y_test).count(2))\n",
    "\n",
    "    # upsample the proportion of high votes to be the same as medium\n",
    "    y_train_12_mask=np.array([True if item in [1,2] else False for item in y_train], dtype=bool)\n",
    "    X_train_12=X_train[y_train_12_mask]\n",
    "    y_train_12=[y_train[x] for x in range(len(y_train)) if y_train_12_mask[x]]\n",
    "    y_train_0_mask=np.array([True if item==0 else False for item in y_train], dtype=bool)\n",
    "    X_train_0=X_train[y_train_0_mask]\n",
    "    \n",
    "    # balance and upsample the high votes:\n",
    "    X_smote_up, y_smote_up=SMOTE().fit_resample(X_train_12, y_train_12)\n",
    "    print(\"in the training data:\")\n",
    "    print(\"number of low votes:\",list(y_train).count(0))\n",
    "    print(\"number of medium votes:\",list(y_smote_up).count(1))\n",
    "    print(\"number of high votes:\",list(y_smote_up).count(2))\n",
    "    \n",
    "    # concate the upsampled class 1,2 with 0, shuffle the order, and then do model training\n",
    "    X_ups_all=np.concatenate((X_train_0,X_smote_up))\n",
    "    y_ups_all=np.concatenate((np.array([0 for x in range(X_train_0.shape[0])]),y_smote_up))\n",
    "    \n",
    "    # assemble a shuffled training dataset\n",
    "    perm=np.random.permutation(X_ups_all.shape[0])\n",
    "    X_train_input=X_ups_all[perm,:]\n",
    "    y_train_input=y_ups_all[perm]\n",
    "    # start off Random Forest , use best parameters\n",
    "    model=RandomForestClassifier(n_estimators=120,\n",
    "     min_samples_split=5,\n",
    "     min_samples_leaf=4,\n",
    "     max_features=10,\n",
    "     max_depth=22,\n",
    "     criterion='gini',\n",
    "     bootstrap=False,verbose=0, n_jobs=-1)\n",
    "    model.fit(X_train_input,y_train_input)\n",
    "    y_pred_test=model.predict(X_test)\n",
    "    \n",
    "    # print the result confusion matrix, save precision/recall/f1\n",
    "    a=precision_recall_fscore_support(y_test, y_pred_test)\n",
    "    print(\"confusion matrix:\")\n",
    "    print(confusion_matrix(y_test,y_pred_test))\n",
    "    print(classification_report(y_test,y_pred_test))\n",
    "    f1s=a[2]\n",
    "    cv_pre_rec+=[a[0]]\n",
    "    cv_recal_rec+=[a[1]]\n",
    "    # create the weighted f1 score: larger emphasis on high-votes bin and medium\n",
    "    # adjusted f1_forall= (f1_low+f1_mid*2+f1_high*3)/6\n",
    "    adjf1=(f1s[0]+f1s[1]*2+f1s[2]*3)/6\n",
    "    print(\"weighted f1 score:\",adjf1)\n",
    "    cv_f1_rec+=[adjf1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final training on a full model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "FinModel=RandomForestClassifier(n_estimators=120,\n",
    "     min_samples_split=5,\n",
    "     min_samples_leaf=4,\n",
    "     max_features=10,\n",
    "     max_depth=22,\n",
    "     criterion='gini',\n",
    "     bootstrap=False,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in the original data:\n",
      "number of low votes: 31611\n",
      "number of medium votes: 1059\n",
      "number of high votes: 210\n",
      "in the upsampled data:\n",
      "number of low votes: 31611\n",
      "number of medium votes: 1059\n",
      "number of high votes: 1059\n"
     ]
    }
   ],
   "source": [
    "# upsampling of the high-votes\n",
    "y_12_mask=np.array([True if item in [1,2] else False for item in y], dtype=bool)\n",
    "X_12=X[y_12_mask]\n",
    "y_12=[y[x] for x in range(len(y)) if y_12_mask[x]]\n",
    "y_0_mask=np.array([True if item==0 else False for item in y], dtype=bool)\n",
    "X_0=X[y_0_mask]\n",
    "\n",
    "# balance and upsample the high votes:\n",
    "X_smote_up, y_smote_up=SMOTE().fit_resample(X_12, y_12)\n",
    "print(\"in the original data:\")\n",
    "print(\"number of low votes:\",list(y).count(0))\n",
    "print(\"number of medium votes:\",list(y).count(1))\n",
    "print(\"number of high votes:\",list(y).count(2))\n",
    "print(\"in the upsampled data:\")\n",
    "print(\"number of low votes:\",list(y).count(0))\n",
    "print(\"number of medium votes:\",list(y_smote_up).count(1))\n",
    "print(\"number of high votes:\",list(y_smote_up).count(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconcate the upsampled class 1,2 with 0, shuffle the order, and then do model training\n",
    "X_ups_all=np.concatenate((X_0,X_smote_up))\n",
    "y_ups_all=np.concatenate((np.array([0 for x in range(X_0.shape[0])]),y_smote_up))\n",
    "\n",
    "# assemble a shuffled training dataset\n",
    "perm=np.random.permutation(X_ups_all.shape[0])\n",
    "X_train_input=X_ups_all[perm,:]\n",
    "y_train_input=y_ups_all[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "                       max_depth=22, max_features=10, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=4, min_samples_split=5,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=120,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FinModel.fit(X_train_input,y_train_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=FinModel.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_prob=FinModel.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=list(zip(y,y_pred,udf['votes'].values,y_prob[:,0],y_prob[:,1],y_prob[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df=pd.DataFrame(result,columns=['class actual','class predicted','actual votes','probability in class0','probability in class1','probability in class2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class actual</th>\n",
       "      <th>class predicted</th>\n",
       "      <th>actual votes</th>\n",
       "      <th>probability in class0</th>\n",
       "      <th>probability in class1</th>\n",
       "      <th>probability in class2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32875</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32876</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999667</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32877</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32878</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.992040</td>\n",
       "      <td>0.002121</td>\n",
       "      <td>0.005838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32879</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.999841</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class actual  class predicted  actual votes  probability in class0  \\\n",
       "32875             0                0             0               0.999963   \n",
       "32876             0                0             0               0.999667   \n",
       "32877             0                0             0               0.999995   \n",
       "32878             0                0             0               0.992040   \n",
       "32879             0                0             0               0.999841   \n",
       "\n",
       "       probability in class1  probability in class2  \n",
       "32875               0.000037               0.000000  \n",
       "32876               0.000229               0.000104  \n",
       "32877               0.000005               0.000000  \n",
       "32878               0.002121               0.005838  \n",
       "32879               0.000102               0.000057  "
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class actual</th>\n",
       "      <th>class predicted</th>\n",
       "      <th>actual votes</th>\n",
       "      <th>probability in class0</th>\n",
       "      <th>probability in class1</th>\n",
       "      <th>probability in class2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>0.303135</td>\n",
       "      <td>0.452579</td>\n",
       "      <td>0.244286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6223</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>79</td>\n",
       "      <td>0.354881</td>\n",
       "      <td>0.150774</td>\n",
       "      <td>0.494345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8604</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0.405956</td>\n",
       "      <td>0.569792</td>\n",
       "      <td>0.024253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24789</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "      <td>0.282427</td>\n",
       "      <td>0.717573</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3219</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>0.440426</td>\n",
       "      <td>0.544454</td>\n",
       "      <td>0.015120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7218</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>0.471607</td>\n",
       "      <td>0.518909</td>\n",
       "      <td>0.009484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22673</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>0.306627</td>\n",
       "      <td>0.341825</td>\n",
       "      <td>0.351548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9935</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>0.459008</td>\n",
       "      <td>0.045099</td>\n",
       "      <td>0.495893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14367</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>0.310238</td>\n",
       "      <td>0.444901</td>\n",
       "      <td>0.244861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22802</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.341329</td>\n",
       "      <td>0.649365</td>\n",
       "      <td>0.009306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15183</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.466237</td>\n",
       "      <td>0.512810</td>\n",
       "      <td>0.020953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25409</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.271789</td>\n",
       "      <td>0.668726</td>\n",
       "      <td>0.059485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class actual  class predicted  actual votes  probability in class0  \\\n",
       "907               0                1            79               0.303135   \n",
       "6223              0                2            79               0.354881   \n",
       "8604              0                1            74               0.405956   \n",
       "24789             0                1            74               0.282427   \n",
       "3219              0                1            71               0.440426   \n",
       "7218              0                1            63               0.471607   \n",
       "22673             0                2            54               0.306627   \n",
       "9935              0                2            33               0.459008   \n",
       "14367             0                1            30               0.310238   \n",
       "22802             0                1            29               0.341329   \n",
       "15183             0                1            12               0.466237   \n",
       "25409             0                1             1               0.271789   \n",
       "\n",
       "       probability in class1  probability in class2  \n",
       "907                 0.452579               0.244286  \n",
       "6223                0.150774               0.494345  \n",
       "8604                0.569792               0.024253  \n",
       "24789               0.717573               0.000000  \n",
       "3219                0.544454               0.015120  \n",
       "7218                0.518909               0.009484  \n",
       "22673               0.341825               0.351548  \n",
       "9935                0.045099               0.495893  \n",
       "14367               0.444901               0.244861  \n",
       "22802               0.649365               0.009306  \n",
       "15183               0.512810               0.020953  \n",
       "25409               0.668726               0.059485  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#show all misclassifications\n",
    "sub0=result_df.loc[result_df['class actual'] == 0]\n",
    "sub1=result_df.loc[result_df['class actual'] == 1]\n",
    "sub2=result_df.loc[result_df['class actual'] == 2]\n",
    "sub0.loc[sub0['class predicted']!=0].sort_values('actual votes',ascending=False) # missclassified low votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class actual</th>\n",
       "      <th>class predicted</th>\n",
       "      <th>actual votes</th>\n",
       "      <th>probability in class0</th>\n",
       "      <th>probability in class1</th>\n",
       "      <th>probability in class2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32526</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9120</td>\n",
       "      <td>0.790625</td>\n",
       "      <td>0.071111</td>\n",
       "      <td>0.138264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32006</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8350</td>\n",
       "      <td>0.794792</td>\n",
       "      <td>0.069028</td>\n",
       "      <td>0.136181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31386</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5176</td>\n",
       "      <td>0.837718</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.159504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30297</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3959</td>\n",
       "      <td>0.886468</td>\n",
       "      <td>0.096587</td>\n",
       "      <td>0.016944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31387</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2515</td>\n",
       "      <td>0.972897</td>\n",
       "      <td>0.027103</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26383</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1468</td>\n",
       "      <td>0.772619</td>\n",
       "      <td>0.047401</td>\n",
       "      <td>0.179980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4758</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1329</td>\n",
       "      <td>0.773926</td>\n",
       "      <td>0.007220</td>\n",
       "      <td>0.218853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32527</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1130</td>\n",
       "      <td>0.935169</td>\n",
       "      <td>0.022560</td>\n",
       "      <td>0.042272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17743</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1126</td>\n",
       "      <td>0.782782</td>\n",
       "      <td>0.012115</td>\n",
       "      <td>0.205103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24007</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1046</td>\n",
       "      <td>0.831925</td>\n",
       "      <td>0.022876</td>\n",
       "      <td>0.145199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27488</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>868</td>\n",
       "      <td>0.721944</td>\n",
       "      <td>0.004940</td>\n",
       "      <td>0.273115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32710</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>836</td>\n",
       "      <td>0.763909</td>\n",
       "      <td>0.112996</td>\n",
       "      <td>0.123095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12482</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>798</td>\n",
       "      <td>0.572503</td>\n",
       "      <td>0.078585</td>\n",
       "      <td>0.348912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25978</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>772</td>\n",
       "      <td>0.721310</td>\n",
       "      <td>0.241131</td>\n",
       "      <td>0.037560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28707</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>0.999425</td>\n",
       "      <td>0.000547</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27368</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>766</td>\n",
       "      <td>0.917044</td>\n",
       "      <td>0.033889</td>\n",
       "      <td>0.049067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16082</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>754</td>\n",
       "      <td>0.634514</td>\n",
       "      <td>0.157401</td>\n",
       "      <td>0.208085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30813</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>751</td>\n",
       "      <td>0.948968</td>\n",
       "      <td>0.046865</td>\n",
       "      <td>0.004167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29918</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>715</td>\n",
       "      <td>0.823720</td>\n",
       "      <td>0.068194</td>\n",
       "      <td>0.108085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32361</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>712</td>\n",
       "      <td>0.958244</td>\n",
       "      <td>0.017242</td>\n",
       "      <td>0.024514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26363</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>679</td>\n",
       "      <td>0.732520</td>\n",
       "      <td>0.110198</td>\n",
       "      <td>0.157282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25317</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>632</td>\n",
       "      <td>0.478522</td>\n",
       "      <td>0.064861</td>\n",
       "      <td>0.456617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24785</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "      <td>0.620387</td>\n",
       "      <td>0.022718</td>\n",
       "      <td>0.356895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27727</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>629</td>\n",
       "      <td>0.985913</td>\n",
       "      <td>0.014087</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15146</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>609</td>\n",
       "      <td>0.588492</td>\n",
       "      <td>0.128869</td>\n",
       "      <td>0.282639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7744</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>607</td>\n",
       "      <td>0.728043</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.267999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22242</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>586</td>\n",
       "      <td>0.683681</td>\n",
       "      <td>0.040942</td>\n",
       "      <td>0.275377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28499</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>568</td>\n",
       "      <td>0.956422</td>\n",
       "      <td>0.043264</td>\n",
       "      <td>0.000314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30814</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>550</td>\n",
       "      <td>0.986865</td>\n",
       "      <td>0.013135</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29919</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>545</td>\n",
       "      <td>0.713284</td>\n",
       "      <td>0.109583</td>\n",
       "      <td>0.177133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4673</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>427</td>\n",
       "      <td>0.576032</td>\n",
       "      <td>0.018492</td>\n",
       "      <td>0.405476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26511</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>424</td>\n",
       "      <td>0.950813</td>\n",
       "      <td>0.025972</td>\n",
       "      <td>0.023214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28422</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>424</td>\n",
       "      <td>0.752659</td>\n",
       "      <td>0.207897</td>\n",
       "      <td>0.039444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31001</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>398</td>\n",
       "      <td>0.853948</td>\n",
       "      <td>0.088968</td>\n",
       "      <td>0.057083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29483</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>396</td>\n",
       "      <td>0.970972</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.018611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9491</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>393</td>\n",
       "      <td>0.716508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25981</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>389</td>\n",
       "      <td>0.943175</td>\n",
       "      <td>0.055635</td>\n",
       "      <td>0.001190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22667</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>384</td>\n",
       "      <td>0.560635</td>\n",
       "      <td>0.143095</td>\n",
       "      <td>0.296270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1557</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>382</td>\n",
       "      <td>0.722060</td>\n",
       "      <td>0.037895</td>\n",
       "      <td>0.240045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25979</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>381</td>\n",
       "      <td>0.647341</td>\n",
       "      <td>0.233512</td>\n",
       "      <td>0.119147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13147</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>373</td>\n",
       "      <td>0.733275</td>\n",
       "      <td>0.037211</td>\n",
       "      <td>0.229515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19805</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>366</td>\n",
       "      <td>0.779156</td>\n",
       "      <td>0.016068</td>\n",
       "      <td>0.204776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32069</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>364</td>\n",
       "      <td>0.632381</td>\n",
       "      <td>0.105853</td>\n",
       "      <td>0.261766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7084</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>359</td>\n",
       "      <td>0.758574</td>\n",
       "      <td>0.003392</td>\n",
       "      <td>0.238034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25980</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>358</td>\n",
       "      <td>0.612480</td>\n",
       "      <td>0.180794</td>\n",
       "      <td>0.206726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27053</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>355</td>\n",
       "      <td>0.862421</td>\n",
       "      <td>0.122937</td>\n",
       "      <td>0.014643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29834</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>354</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.030298</td>\n",
       "      <td>0.043036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20311</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>353</td>\n",
       "      <td>0.708637</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.287250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16089</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "      <td>0.480357</td>\n",
       "      <td>0.080615</td>\n",
       "      <td>0.439028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31117</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>340</td>\n",
       "      <td>0.955238</td>\n",
       "      <td>0.015060</td>\n",
       "      <td>0.029702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26293</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>340</td>\n",
       "      <td>0.956944</td>\n",
       "      <td>0.040972</td>\n",
       "      <td>0.002083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31477</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>339</td>\n",
       "      <td>0.955774</td>\n",
       "      <td>0.019583</td>\n",
       "      <td>0.024643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5311</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>337</td>\n",
       "      <td>0.725437</td>\n",
       "      <td>0.031796</td>\n",
       "      <td>0.242768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28356</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>336</td>\n",
       "      <td>0.995956</td>\n",
       "      <td>0.004017</td>\n",
       "      <td>0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27875</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>328</td>\n",
       "      <td>0.880585</td>\n",
       "      <td>0.099742</td>\n",
       "      <td>0.019673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10427</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>325</td>\n",
       "      <td>0.847245</td>\n",
       "      <td>0.060712</td>\n",
       "      <td>0.092043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32797</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>319</td>\n",
       "      <td>0.867917</td>\n",
       "      <td>0.093214</td>\n",
       "      <td>0.038869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10788</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>317</td>\n",
       "      <td>0.619683</td>\n",
       "      <td>0.059385</td>\n",
       "      <td>0.320933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30816</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "      <td>0.841885</td>\n",
       "      <td>0.071667</td>\n",
       "      <td>0.086448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3781</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>304</td>\n",
       "      <td>0.221084</td>\n",
       "      <td>0.486930</td>\n",
       "      <td>0.291985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       class actual  class predicted  actual votes  probability in class0  \\\n",
       "32526             2                0          9120               0.790625   \n",
       "32006             2                0          8350               0.794792   \n",
       "31386             2                0          5176               0.837718   \n",
       "30297             2                0          3959               0.886468   \n",
       "31387             2                0          2515               0.972897   \n",
       "26383             2                0          1468               0.772619   \n",
       "4758              2                0          1329               0.773926   \n",
       "32527             2                0          1130               0.935169   \n",
       "17743             2                0          1126               0.782782   \n",
       "24007             2                0          1046               0.831925   \n",
       "27488             2                0           868               0.721944   \n",
       "32710             2                0           836               0.763909   \n",
       "12482             2                0           798               0.572503   \n",
       "25978             2                0           772               0.721310   \n",
       "28707             2                0           767               0.999425   \n",
       "27368             2                0           766               0.917044   \n",
       "16082             2                0           754               0.634514   \n",
       "30813             2                0           751               0.948968   \n",
       "29918             2                0           715               0.823720   \n",
       "32361             2                0           712               0.958244   \n",
       "26363             2                0           679               0.732520   \n",
       "25317             2                0           632               0.478522   \n",
       "24785             2                0           630               0.620387   \n",
       "27727             2                0           629               0.985913   \n",
       "15146             2                0           609               0.588492   \n",
       "7744              2                0           607               0.728043   \n",
       "22242             2                0           586               0.683681   \n",
       "28499             2                0           568               0.956422   \n",
       "30814             2                0           550               0.986865   \n",
       "29919             2                0           545               0.713284   \n",
       "...             ...              ...           ...                    ...   \n",
       "4673              2                0           427               0.576032   \n",
       "26511             2                0           424               0.950813   \n",
       "28422             2                0           424               0.752659   \n",
       "31001             2                0           398               0.853948   \n",
       "29483             2                0           396               0.970972   \n",
       "9491              2                0           393               0.716508   \n",
       "25981             2                0           389               0.943175   \n",
       "22667             2                0           384               0.560635   \n",
       "1557              2                0           382               0.722060   \n",
       "25979             2                0           381               0.647341   \n",
       "13147             2                0           373               0.733275   \n",
       "19805             2                0           366               0.779156   \n",
       "32069             2                0           364               0.632381   \n",
       "7084              2                0           359               0.758574   \n",
       "25980             2                0           358               0.612480   \n",
       "27053             2                0           355               0.862421   \n",
       "29834             2                0           354               0.926667   \n",
       "20311             2                0           353               0.708637   \n",
       "16089             2                0           348               0.480357   \n",
       "31117             2                0           340               0.955238   \n",
       "26293             2                0           340               0.956944   \n",
       "31477             2                0           339               0.955774   \n",
       "5311              2                0           337               0.725437   \n",
       "28356             2                0           336               0.995956   \n",
       "27875             2                0           328               0.880585   \n",
       "10427             2                0           325               0.847245   \n",
       "32797             2                0           319               0.867917   \n",
       "10788             2                0           317               0.619683   \n",
       "30816             2                0           312               0.841885   \n",
       "3781              2                1           304               0.221084   \n",
       "\n",
       "       probability in class1  probability in class2  \n",
       "32526               0.071111               0.138264  \n",
       "32006               0.069028               0.136181  \n",
       "31386               0.002778               0.159504  \n",
       "30297               0.096587               0.016944  \n",
       "31387               0.027103               0.000000  \n",
       "26383               0.047401               0.179980  \n",
       "4758                0.007220               0.218853  \n",
       "32527               0.022560               0.042272  \n",
       "17743               0.012115               0.205103  \n",
       "24007               0.022876               0.145199  \n",
       "27488               0.004940               0.273115  \n",
       "32710               0.112996               0.123095  \n",
       "12482               0.078585               0.348912  \n",
       "25978               0.241131               0.037560  \n",
       "28707               0.000547               0.000028  \n",
       "27368               0.033889               0.049067  \n",
       "16082               0.157401               0.208085  \n",
       "30813               0.046865               0.004167  \n",
       "29918               0.068194               0.108085  \n",
       "32361               0.017242               0.024514  \n",
       "26363               0.110198               0.157282  \n",
       "25317               0.064861               0.456617  \n",
       "24785               0.022718               0.356895  \n",
       "27727               0.014087               0.000000  \n",
       "15146               0.128869               0.282639  \n",
       "7744                0.003958               0.267999  \n",
       "22242               0.040942               0.275377  \n",
       "28499               0.043264               0.000314  \n",
       "30814               0.013135               0.000000  \n",
       "29919               0.109583               0.177133  \n",
       "...                      ...                    ...  \n",
       "4673                0.018492               0.405476  \n",
       "26511               0.025972               0.023214  \n",
       "28422               0.207897               0.039444  \n",
       "31001               0.088968               0.057083  \n",
       "29483               0.010417               0.018611  \n",
       "9491                0.000000               0.283492  \n",
       "25981               0.055635               0.001190  \n",
       "22667               0.143095               0.296270  \n",
       "1557                0.037895               0.240045  \n",
       "25979               0.233512               0.119147  \n",
       "13147               0.037211               0.229515  \n",
       "19805               0.016068               0.204776  \n",
       "32069               0.105853               0.261766  \n",
       "7084                0.003392               0.238034  \n",
       "25980               0.180794               0.206726  \n",
       "27053               0.122937               0.014643  \n",
       "29834               0.030298               0.043036  \n",
       "20311               0.004113               0.287250  \n",
       "16089               0.080615               0.439028  \n",
       "31117               0.015060               0.029702  \n",
       "26293               0.040972               0.002083  \n",
       "31477               0.019583               0.024643  \n",
       "5311                0.031796               0.242768  \n",
       "28356               0.004017               0.000028  \n",
       "27875               0.099742               0.019673  \n",
       "10427               0.060712               0.092043  \n",
       "32797               0.093214               0.038869  \n",
       "10788               0.059385               0.320933  \n",
       "30816               0.071667               0.086448  \n",
       "3781                0.486930               0.291985  \n",
       "\n",
       "[65 rows x 6 columns]"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub2.loc[sub2['class predicted']!=2].sort_values('actual votes',ascending=False) # missclassified high votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the prediction to dataframe\n",
    "result_df.to_csv('EventfulFinalMod_result111819.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "import dill\n",
    "# save the model to disk\n",
    "filename = 'finalized_model111819.sav'\n",
    "#pickle.dump(FinModel, open(filename, 'wb'))\n",
    "### suggestion for loading the model from disk\n",
    "### loaded_model = pickle.load(open(filename, 'rb'))\n",
    "with open(filename, \"wb\") as dill_file:\n",
    "    dill.dump(FinModel, dill_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MinMaxScalar_111819.pkl']"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the scalar for X input, for later useage :\n",
    "from sklearn.externals import joblib  \n",
    "\n",
    "# 'dump' scalar file\n",
    "joblib.dump(scalar, 'MinMaxScalar_111819.pkl') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
